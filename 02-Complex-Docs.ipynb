{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "60ec6048-44e4-4118-b16a-9c4c9cc78a3b",
      "metadata": {},
      "source": [
        "# How to deal with complex/large Documents"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9281ac79-47cd-49d4-bdd4-7f5c173a947d",
      "metadata": {},
      "source": [
        "이전 노트북에서는 조직에서 흔히 볼 수 있는 다양한 유형의 파일과 데이터 형식에 대한 솔루션을 개발했으며, 이는 대부분의 사용 사례를 다룹니다. 하지만 복잡한 파일에서 답을 찾아야 하는 질문을 처리할 때 문제가 있다는 것을 알게 될 것입니다. 이러한 파일의 복잡성은 파일의 길이와 그 안에 정보가 분산되어 있는 방식에서 비롯됩니다. 대용량 문서는 검색 엔진에게 항상 어려운 과제입니다.\n",
        "\n",
        "이러한 복잡한 파일의 한 예로 수백 페이지에 달하고 이미지, 표, 양식 등의 형태로 정보를 포함하는 기술 사양 가이드나 제품 설명서를 들 수 있습니다. 책 역시 그 길이와 이미지나 표의 존재로 인해 복잡합니다.\n",
        "\n",
        "이러한 파일은 일반적으로 PDF 형식으로 되어 있습니다. 이러한 PDF를 더 잘 처리하려면 각 문서를 특별한 소스로 취급하고 페이지 단위(1페이지=1청크)로 처리하는 더 스마트한 파싱 방법이 필요합니다. 목표는 시스템에서 더 정확하고 빠른 답변을 얻는 것입니다. 다행히도 조직에는 일반적으로 이러한 유형의 문서가 많지 않으므로 예외를 만들어 다르게 처리할 수 있습니다.\n",
        "\n",
        "예를 들어 사용 사례가 PDF인 경우 PyPDF 라이브러리 (https://pypi.org/project/pypdf/) 또는 Azure AI Document Intelligence SDK(이전 Form Recognizer) (https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/overview?view=doc-intel-3.0.0) 를 사용하고 OpenAI API를 사용하여 벡터화하여 콘텐츠를 벡터 기반 인덱스로 푸시할 수 있습니다. 이것이 아마도 가장 간단하고 빠른 방법일 것입니다. 그러나 사용 사례에 데이터 레이크, Sharepoint 라이브러리 또는 여러 파일 형식의 수천 개의 문서가 있고 동적으로 변경될 수 있는 기타 문서 데이터 소스에 연결해야 하는 경우에는 Azure 검색 엔진, 노트북 1-2의 수집 및 문서 크래킹 및 AI 강화 기능을 사용하여 많은 사용자 지정 코드를 피하고 싶을 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15f6044e-463f-4988-bc46-a3c3d641c15c",
      "metadata": {
        "gather": {
          "logged": 1713768375401
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "from common.utils import parse_pdf, read_pdf_files, text_to_base64\n",
        "from common.prompts import DOCSEARCH_PROMPT\n",
        "from common.utils import CustomAzureSearchRetriever\n",
        "\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "    \n",
        "os.makedirs(\"data/techdocs/\",exist_ok=True)\n",
        "\n",
        "# Name of the container in your Blob Storage Datasource ( in credentials.env) \n",
        "BLOB_CONTAINER_NAME = \"techdocs\"\n",
        "\n",
        "c = os.environ[\"BLOB_CONNECTION_STRING\"].split(\";\")\n",
        "BASE_CONTAINER_URL = c[0].split(\"=\")[1] + BLOB_CONTAINER_NAME + \"/\"\n",
        "\n",
        "LOCAL_FOLDER = \"./data/techdocs/\"\n",
        "\n",
        "os.makedirs(LOCAL_FOLDER,exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "331692ba-b68e-4b99-9bae-5057da9a389d",
      "metadata": {
        "gather": {
          "logged": 1713768377206
        }
      },
      "outputs": [],
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "594ff0d4-56e3-4bed-843d-28c7a092069b",
      "metadata": {
        "gather": {
          "logged": 1713768378787
        }
      },
      "outputs": [],
      "source": [
        "embedder = AzureOpenAIEmbeddings(deployment=os.environ[\"EMBEDDING_DEPLOYMENT_NAME\"], chunk_size=1) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb87c647-158c-4f85-b569-5b9462f06c83",
      "metadata": {},
      "source": [
        "## 1 - Manual Document Cracking with Push to Vector-based Index"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "75551868-1546-421b-a14e-e42618d88e61",
      "metadata": {},
      "source": [
        "Azure Service에 대한 PDF 기술 문서를 보관하는 techdocs 라는 이름의 컨테이너가 있습니다. 이 모든 책의 페이지가 담긴 cogsrch-index-techdocs 인덱스를 생성하여 로드해 보겠습니다.\n",
        "\n",
        "먼저 이 책들을 로컬 머신에 다운로드합니다. 여기에서는 빠른 테스트를 위해 각 서비스의 Overview 섹션만을 인덱싱합니다. 전체 문서를 인덱싱하고저 하는 경우 아래 파일명을 변경하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65ff5fcc",
      "metadata": {
        "gather": {
          "logged": 1713768382219
        }
      },
      "outputs": [],
      "source": [
        "techdocs = [\"Azure_Cognitive_Search_Documentation_Overview.pdf\", \"Azure_AI_services_Document_Intelligence_Documentation_Overview.pdf\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd867b2f-b5a1-443c-aa0a-ce914a66b3c9",
      "metadata": {},
      "source": [
        "Let's download the files to the local `./data/` folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3554f0b7-fee8-4446-a155-5d22dc0f0888",
      "metadata": {
        "gather": {
          "logged": 1713768386435
        }
      },
      "outputs": [],
      "source": [
        "# Blob에 있는 PDF를 Local로 다운로드하는 부분\n",
        "\n",
        "for book in tqdm(techdocs):\n",
        "    book_url = BASE_CONTAINER_URL + book + os.environ['BLOB_SAS_TOKEN']\n",
        "    urllib.request.urlretrieve(book_url, LOCAL_FOLDER+ book)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "788cc0db-9dae-45f2-8943-2b6fa32fcc75",
      "metadata": {},
      "source": [
        "### What to use: pyPDF or AI Documment Intelligence API (Form Recognizer)?\n",
        "\n",
        "'utils.py'에는 **parse_pdf()** 함수가 있습니다. 이 유틸리티 함수는 PyPDF 라이브러리를 사용하여 로컬 파일을 구문 분석할 수 있으며, Azure AI Document Intelligence(이전 양식 인식기)를 사용하여 로컬 또는 from_url PDF 파일을 구문 분석할 수도 있습니다.\n",
        "\n",
        "`form_recognizer=False`인 경우, 이 함수는 파이썬 pyPDF 라이브러리를 사용하여 PDF를 구문 분석하며, 75%의 경우 제대로 작동합니다.<br>\n",
        "\n",
        "`form_recognizer=True`를 설정하는 것은 AI 문서 인텔리전스 API(이전의 양식 인식기)를 사용하는 가장 좋은(그리고 느린) 구문 분석 방법입니다. 사용할 사전 구축 모델을 지정할 수 있으며, 기본값은 `model=\"prebuilt-document\"`입니다. 그러나 표, 차트 및 그림이 포함된 복잡한 문서가 있는 경우 다음을 사용해 볼 수 있습니다.\n",
        "model=\"prebuilt-layout\"`을 사용하면 각 페이지의 모든 뉘앙스를 포착할 수 있습니다(물론 시간이 더 오래 걸립니다).\n",
        "\n",
        "**참고: 많은 PDF는 스캔 이미지입니다. 예를 들어, 스캔하여 PDF로 저장한 서명된 계약서는 pyPDF에서 파싱되지 않습니다. AI 문서 인텔리전스 API만 작동합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1c63a2f-7a53-4346-8a1f-483cfd159d34",
      "metadata": {
        "gather": {
          "logged": 1713768671655
        }
      },
      "outputs": [],
      "source": [
        "book_pages_map = dict()\n",
        "for book in techdocs:\n",
        "    print(\"Extracting Text from\",book,\"...\")\n",
        "    \n",
        "    # Capture the start time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Parse the PDF\n",
        "    book_path = LOCAL_FOLDER+book\n",
        "    book_map = parse_pdf(file=book_path, form_recognizer=True, model=\"prebuilt-document\", from_url=False, verbose=True)\n",
        "    book_pages_map[book]= book_map\n",
        "    \n",
        "    # Capture the end time and Calculate the elapsed time\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    print(f\"Parsing took: {elapsed_time:.6f} seconds\")\n",
        "    print(f\"{book} contained {len(book_map)} pages\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5de0a722-ae0c-4b57-802a-518f5d4d93fd",
      "metadata": {},
      "source": [
        "Now let's check a random page of each book to make sure the parsing was done correctly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2a5d62f-b664-4662-a6c9-a1eb2a3c5e11",
      "metadata": {
        "gather": {
          "logged": 1713769507804
        }
      },
      "outputs": [],
      "source": [
        "for bookname,bookmap in book_pages_map.items():\n",
        "    print(bookname,\"\\n\",\"chunk text:\",bookmap[random.randint(0, 29)][2][:120],\"...\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9c279dfb-4fed-41b8-89e1-0ca2cefbcdc9",
      "metadata": {},
      "source": [
        "위에서 살펴본 바와 같이 Azure Document Intelligence는 pyPDF보다 우수하다는 것이 입증되었습니다. **프로덕션 시나리오의 경우 Azure Document Intelligence를 지속적으로 사용할 것을 강력히 권장합니다**. 이 경우 '미리 빌드된 문서', '미리 빌드된 레이아웃' 등의 사용 가능한 모델 중에서 현명한 선택을 하는 것이 중요합니다. 모델 선택에 대한 자세한 내용은 [여기](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/choose-model-feature?view=doc-intel-3.0.0)에서 확인할 수 있습니다.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7f5f9b7d-99e6-426d-a47e-343c7e8b492e",
      "metadata": {},
      "source": [
        "## Create Vector-based index\n",
        "\n",
        "\n",
        "이제 책의 청크(각 책의 각 페이지)의 콘텐츠가 사전 `book_pages_map`에 있으므로 이 콘텐츠가 위치할 Azure 검색 엔진에 벡터 인덱스를 생성해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d46e7c5-49c4-40f3-bb2d-79a9afeab4b1",
      "metadata": {
        "gather": {
          "logged": 1713769548685
        }
      },
      "outputs": [],
      "source": [
        "book_index_name = \"cogsrch-index-techdocs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b07e84b-d306-4bc9-9124-e64f252dd7b2",
      "metadata": {
        "gather": {
          "logged": 1713769551395
        }
      },
      "outputs": [],
      "source": [
        "### Create Azure Search Vector-based Index\n",
        "# Setup the Payloads header\n",
        "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
        "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2faab899-977b-40d0-b36e-26f75ac07e54",
      "metadata": {},
      "source": [
        "Index와 관련하여 다음 사항에 유의하세요.\n",
        "\n",
        "- ParentKey(부모 키) 필드가 없습니다.\n",
        "- page_num 필드가 존재합니다.\n",
        "\n",
        "ParentKey 필드가 없는 것은 PULL 방식이 아닌 PUSH 방식을 활용하기 때문입니다. 이 접근 방식은 Azure AI 검색 엔진에서 제공하는 통합 인덱싱을 활용하지 않고 있음을 나타냅니다. 대신 구문 분석, OCR 수행, 벡터와 함께 콘텐츠를 수동으로 생성 및 푸시하는 프로세스에 참여하고 있습니다.\n",
        "\n",
        "이 수동 구문 분석 프로세스에는 pyPDF 라이브러리 또는 Azure Document Intelligence API가 사용됩니다. 이러한 API를 사용하면 지정된 문자 수가 아닌 페이지별로 콘텐츠를 세분화할 수 있으며, 이는 Azure AI 검색 인덱서에서 사용하는 방법입니다. 따라서 인덱스에 page_num을 필드로 포함할 수 있습니다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "75d63e68-69a5-4b3b-8eb0-86da02cb7230",
      "metadata": {},
      "source": [
        "\n",
        "REST API 버전 2023-10-01-프리뷰는 외부 및 내부 벡터화를 지원합니다. 이 노트북은 외부 벡터화 전략을 가정합니다. 이 API는 또한\n",
        "\n",
        "인덱싱 및 점수 매기기 위한 매개변수와 함께 vectorSearch 알고리즘, hnsw 및 exhaustiveKnn 최접근 이웃.\n",
        "알고리즘 구성의 여러 조합을 위한 vectorProfiles.\n",
        "벡터 검색 알고리즘에는 완전 k-최근접 이웃(KNN) 및 계층적 탐색 가능한 작은 세계(HNSW)가 포함됩니다. 완전 KNN은 전체 벡터 공간을 스캔하는 무차별 검색을 수행합니다. HNSW는 대략적인 최인접 이웃(ANN) 검색을 수행합니다. KNN은 높은 정확도로 정확한 최근접 이웃 검색 결과를 제공하지만, 계산 비용과 낮은 확장성으로 인해 대규모 데이터 세트나 실시간 애플리케이션에는 비현실적입니다. 반면, HNSW는 대략적인 가장 가까운 이웃을 빠르게 찾아내어 가장 가까운 이웃 검색을 위한 매우 효율적이고 확장 가능한 솔루션을 제공하므로 대규모 및 고차원 데이터 애플리케이션에 더 적합합니다.\n",
        "\n",
        "벡터 구성에 대한 자세한 내용은 여기에서 확인하세요.\n",
        "https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-create-index?tabs=config-2023-10-01-Preview%2Crest-2023-11-01%2Cpush%2Cportal-check-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2df4db6b-969b-4b91-963f-9334e17a4e3c",
      "metadata": {
        "gather": {
          "logged": 1713769555136
        }
      },
      "outputs": [],
      "source": [
        "index_payload = {\n",
        "    \"name\": book_index_name,\n",
        "    \"vectorSearch\": {\n",
        "        \"algorithms\": [  # We are showing here 3 types of search algorithms configurations that you can do\n",
        "             {\n",
        "                 \"name\": \"my-hnsw-config-1\",\n",
        "                 \"kind\": \"hnsw\",\n",
        "                 \"hnswParameters\": {\n",
        "                     \"m\": 4,\n",
        "                     \"efConstruction\": 400,\n",
        "                     \"efSearch\": 500,\n",
        "                     \"metric\": \"cosine\"\n",
        "                 }\n",
        "             },\n",
        "             {\n",
        "                 \"name\": \"my-hnsw-config-2\",\n",
        "                 \"kind\": \"hnsw\",\n",
        "                 \"hnswParameters\": {\n",
        "                     \"m\": 8,\n",
        "                     \"efConstruction\": 800,\n",
        "                     \"efSearch\": 800,\n",
        "                     \"metric\": \"cosine\"\n",
        "                 }\n",
        "             },\n",
        "             {\n",
        "                 \"name\": \"my-eknn-config\",\n",
        "                 \"kind\": \"exhaustiveKnn\",\n",
        "                 \"exhaustiveKnnParameters\": {\n",
        "                     \"metric\": \"cosine\"\n",
        "                 }\n",
        "             }\n",
        "        ],\n",
        "        \"vectorizers\": [\n",
        "            {\n",
        "                \"name\": \"openai\",\n",
        "                \"kind\": \"azureOpenAI\",\n",
        "                \"azureOpenAIParameters\":\n",
        "                {\n",
        "                    \"resourceUri\" : os.environ['AZURE_OPENAI_ENDPOINT'],\n",
        "                    \"apiKey\" : os.environ['AZURE_OPENAI_API_KEY'],\n",
        "                    \"deploymentId\" : os.environ['EMBEDDING_DEPLOYMENT_NAME']\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        \"profiles\": [  # profiles is the diferent kind of combinations of algos and vectorizers\n",
        "            {\n",
        "             \"name\": \"my-vector-profile-1\",\n",
        "             \"algorithm\": \"my-hnsw-config-1\",\n",
        "             \"vectorizer\":\"openai\"\n",
        "            },\n",
        "            {\n",
        "             \"name\": \"my-vector-profile-2\",\n",
        "             \"algorithm\": \"my-hnsw-config-2\",\n",
        "             \"vectorizer\":\"openai\"\n",
        "            },\n",
        "            {\n",
        "             \"name\": \"my-vector-profile-3\",\n",
        "             \"algorithm\": \"my-eknn-config\",\n",
        "             \"vectorizer\":\"openai\"\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"semantic\": {\n",
        "        \"configurations\": [\n",
        "            {\n",
        "                \"name\": \"my-semantic-config\",\n",
        "                \"prioritizedFields\": {\n",
        "                    \"titleField\": {\n",
        "                        \"fieldName\": \"title\"\n",
        "                    },\n",
        "                    \"prioritizedContentFields\": [\n",
        "                        {\n",
        "                            \"fieldName\": \"chunk\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"prioritizedKeywordsFields\": []\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"fields\": [\n",
        "        {\"name\": \"id\", \"type\": \"Edm.String\", \"key\": \"true\", \"filterable\": \"true\" },\n",
        "        {\"name\": \"title\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
        "        {\"name\": \"chunk\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
        "        {\"name\": \"name\", \"type\": \"Edm.String\", \"searchable\": \"true\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
        "        {\"name\": \"location\", \"type\": \"Edm.String\", \"searchable\": \"false\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
        "        {\"name\": \"page_num\",\"type\": \"Edm.Int32\",\"searchable\": \"false\",\"retrievable\": \"true\"},\n",
        "        {\n",
        "            \"name\": \"chunkVector\",\n",
        "            \"type\": \"Collection(Edm.Single)\",\n",
        "            \"dimensions\": 1536,\n",
        "            \"vectorSearchProfile\": \"my-vector-profile-3\", # we picked profile 3 to show that this index uses eKNN vs HNSW (on prior notebooks)\n",
        "            \"searchable\": \"true\",\n",
        "            \"retrievable\": \"true\",\n",
        "            \"filterable\": \"false\",\n",
        "            \"sortable\": \"false\",\n",
        "            \"facetable\": \"false\"\n",
        "        }\n",
        "        \n",
        "    ],\n",
        "}\n",
        "\n",
        "r = requests.put(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name,\n",
        "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
        "print(r.status_code)\n",
        "print(r.ok)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36691ff0-c4c8-49d0-bfa8-3e076ece0ce5",
      "metadata": {
        "gather": {
          "logged": 1713623829521
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment to debug errors\n",
        "# r.text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bc7dda9-4725-410e-9465-54f0298fc758",
      "metadata": {},
      "source": [
        "## 문서 청크와 해당 벡터를 인덱스에 업로드"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d73e7600-7902-48d4-b199-9d9dc0a17aa0",
      "metadata": {},
      "source": [
        "\n",
        "다음 코드는 각 도서의 각 청크를 반복하고 Azure Search Rest API 업로드 방법을 사용하여 각 문서를 해당 벡터(OpenAI 임베딩 모델 사용)와 함께 인덱스에 삽입합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5c8aa55-1b60-4057-93db-0d4a89993a57",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "for bookname,bookmap in book_pages_map.items():\n",
        "    print(\"Uploading chunks from\",bookname)\n",
        "    for page in tqdm(bookmap):\n",
        "        try:\n",
        "            page_num = page[0] + 1\n",
        "            content = page[2]\n",
        "            book_url = BASE_CONTAINER_URL + bookname\n",
        "            upload_payload = {\n",
        "                \"value\": [\n",
        "                    {\n",
        "                        \"id\": text_to_base64(bookname + str(page_num)),\n",
        "                        \"title\": f\"{bookname}_page_{str(page_num)}\",\n",
        "                        \"chunk\": content,\n",
        "                        \"chunkVector\": embedder.embed_query(content if content!=\"\" else \"-------\"),\n",
        "                        \"name\": bookname,\n",
        "                        \"location\": book_url,\n",
        "                        \"page_num\": page_num,\n",
        "                        \"@search.action\": \"upload\"\n",
        "                    },\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name + \"/docs/index\",\n",
        "                                 data=json.dumps(upload_payload), headers=headers, params=params)\n",
        "            if r.status_code != 200:\n",
        "                print(r.status_code)\n",
        "                print(r.text)\n",
        "        except Exception as e:\n",
        "            print(\"Exception:\",e)\n",
        "            print(content)\n",
        "            continue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "715cddcf-af7b-4006-a047-853fc7a66be3",
      "metadata": {},
      "source": [
        "## Query the Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b408798-5527-44ca-9dba-cad2ee726aca",
      "metadata": {
        "gather": {
          "logged": 1713623927099
        }
      },
      "outputs": [],
      "source": [
        "#QUESTION = \"What's Azure AI Search?\"\n",
        "QUESTION = \"Can I move, backup, and restore indexes?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b182ade-0ddd-47a1-b1eb-2cbf435c317f",
      "metadata": {
        "gather": {
          "logged": 1713623928701
        }
      },
      "outputs": [],
      "source": [
        "indexes = [book_index_name]\n",
        "k=10 # in this index k corresponds to the top pages as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d50eecb2-ce26-4127-a62b-79735b937046",
      "metadata": {
        "gather": {
          "logged": 1713623929721
        }
      },
      "outputs": [],
      "source": [
        "retriever = CustomAzureSearchRetriever(indexes=[book_index_name], topK=k, reranker_threshold=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdd2f3f2-2d66-4bd4-b90b-d30970b71af4",
      "metadata": {},
      "source": [
        "**Note**: 이 청크는 이전 노트북처럼 각각 5000자가 아니라 각 페이지가 청크이기 때문에 더 큰 k=20을 선택한다는 것을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "410ff796-dab1-4817-a3a5-82eeff6c0c57",
      "metadata": {
        "gather": {
          "logged": 1713623931387
        }
      },
      "outputs": [],
      "source": [
        "COMPLETION_TOKENS = 2500\n",
        "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS).configurable_alternatives(\n",
        "    ConfigurableField(id=\"model\"),\n",
        "    default_key=\"gpt35\",\n",
        "    gpt4=AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0, max_tokens=COMPLETION_TOKENS),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef5d4216",
      "metadata": {},
      "source": [
        "In `utils.py` we created the **CustomAzureSearchRetriever** class that we will use going forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26f47c69-44d8-48e3-974e-7989b4a8b7c5",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "chain = (\n",
        "    {\n",
        "        \"context\": itemgetter(\"question\") | retriever, # Passes the question to the retriever and the results are assign to context\n",
        "        \"question\": itemgetter(\"question\")\n",
        "    }\n",
        "    | DOCSEARCH_PROMPT  # Passes the 4 variables above to the prompt template\n",
        "    | llm   # Passes the finished prompt to the LLM\n",
        "    | StrOutputParser()  # converts the output (Runnable object) to the desired output (string)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "765df250-af7f-46c9-8d7a-15c0522969ec",
      "metadata": {},
      "source": [
        "#### With GPT 3.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73f34192-519d-45b9-a0e2-a8b2de51ee1e",
      "metadata": {
        "gather": {
          "logged": 1713623789372
        }
      },
      "outputs": [],
      "source": [
        "for chunk in chain.with_config(configurable={\"model\": \"gpt35\"}).stream({\"question\": QUESTION}):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4a8761d-2c1e-4369-b7c4-c3571a0793e9",
      "metadata": {},
      "source": [
        "#### With GPT 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b77511-b178-4c9b-9fa5-fdddb0d3e586",
      "metadata": {
        "gather": {
          "logged": 1713623789394
        }
      },
      "outputs": [],
      "source": [
        "for chunk in chain.with_config(configurable={\"model\": \"gpt4\"}).stream(\n",
        "    {\"question\": QUESTION, \"language\": \"English\"}):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3941796c-7655-4888-a358-8a62e380bd7e",
      "metadata": {},
      "source": [
        "# Summary\n",
        "\n",
        "이 노트북에서는 [하이브리드 검색](https://learn.microsoft.com/en-us/azure/search/search-get-started-vector#hybrid-search)(텍스트 + 벡터 검색)을 사용하여 복잡하고 큰 문서를 처리하고 이를 Q&A에 사용할 수 있도록 하는 방법을 배웠습니다.\n",
        "\n",
        "\n",
        "또한 Azure Document Intelligence API의 성능과 수동 문서 구문 분석이 필요한 프로덕션 시나리오(Azure Search 인덱서 문서 크래킹 대신)에 권장되는 이유에 대해 알아봤습니다.\n",
        "\n",
        "\n",
        "벡터 기능 및 하이브리드 검색 기능과 함께 Azure AI Search를 사용하면 Weaviate, Qdrant, Milvus, Pinecone 등과 같은 다른 벡터 데이터베이스가 필요하지 않습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85d9a7d1-f029-416b-8eb2-00a8afb9151d",
      "metadata": {},
      "source": [
        "# NEXT\n",
        "지금까지 Azure AI Search에 저장된 문서에서 우수한 답변을 얻기 위해 OpenAI 벡터 및 완성 API를 사용하는 방법에 대해 알아봤습니다. 이것이 바로 `GPT 스마트 검색 엔진`의 근간이 됩니다.\n",
        "\n",
        "하지만 뭔가 빠진 것이 있습니다: 바로 **이 엔진과 대화하는 방법**입니다.\n",
        "\n",
        "\n",
        "다음 노트북에서는 **메모리**의 개념을 이해해 보겠습니다. 이는 사용자와 대화를 나눌 수 있는 챗봇을 만들기 위해 필요합니다. 메모리가 없으면 실제 대화가 불가능합니다."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

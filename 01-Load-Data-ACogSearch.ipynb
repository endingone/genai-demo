{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Introduction\n",
        "\n",
        "이 리포지토리에 오신 것을 환영합니다. RAG(검색 증강 생성, 검색의 힘과 AI 생성을 결합하여 사용자 쿼리에 답하는 기술)의 작동 방식을 이해하는 일련의 노트북으로 안내해 드리겠습니다. 이 노트북의 마지막 부분에서는 Azure AI Search와 함께 작업하며, 이 조합으로 마법이 일어나는 이유를 이해하게 될 것입니다:\n",
        "\n",
        "1) 단일 에이전트 \n",
        "2) Azure OpenAI 모델 \n",
        "3) 매우 상세한 프롬프트\n",
        "\n",
        "하지만 기본부터 시작해야 하므로 Azure AI Search와 그 작동 방식부터 시작하겠습니다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load and Enrich multiple file types Azure AI Search\n",
        "\n",
        "이 Jupyter 노트북에서는 지정된 Azure 블롭에서 검색 가능한 콘텐츠를 잠금 해제하기 위한 강화 단계를 만들고 실행합니다. 이미지 및 애플리케이션 파일과 같은 Azure 저장소의 혼합 콘텐츠에 대한 작업을 수행하며, Azure 인지 검색에서 검색 가능한 텍스트 정보를 분석하고 추출하는 스킬셋을 사용합니다. 참조 샘플은 자습서: Python 및 AI를 사용하여 Azure 블롭에서 검색 가능한 콘텐츠 생성에서 찾을 수 있습니다 [Tutorial: Use Python and AI to generate searchable content from Azure blobs](https://docs.microsoft.com/azure/search/cognitive-search-tutorial-blob-python).\n",
        "\n",
        "이 데모에서는 Azure AI 검색 샘플 데이터에서 ~9.8k Contoso Electronics HR PDF가 있는 비공개(프라이빗 데이터 레이크 시나리오를 모방할 수 있도록) Blob Storage 컨테이너를 사용하겠습니다. https://github.com/Azure-Samples/azure-search-sample-data/tree/main\n",
        "\n",
        "참고: 이 데이터 집합은 이 데모를 위해 공용 Azure 블롭 컨테이너에 복사되었습니다.\n",
        "\n",
        "여기서는 PDF 파일만 사용되었지만 훨씬 더 큰 규모에서 이 작업을 수행할 수 있으며 Azure AI Search는 다음과 같은 다양한 파일 형식을 지원합니다. \n",
        "- Microsoft Office(DOCX/DOC, XSLX/XLS, PPTX/PPT, MSG), HTML, XML, ZIP 및 일반 텍스트 파일(JSON 포함).\n",
        "\n",
        "이 노트북은 검색 서비스에서 다음 개체를 만듭니다.\n",
        "\n",
        "+ data source\n",
        "+ search index\n",
        "+ skillset\n",
        "+ indexer\n",
        "\n",
        "이 노트북에서는 Search REST APIs를 호출하지만, Python용 Azure SDK의 Azure.Search.Documents 클라이언트 라이브러리를 사용하여 동일한 단계를 수행할 수도 있습니다. 자세한 내용은 이 Python 빠른 시작을 참조하세요.\n",
        "\n",
        "이 노트북을 실행하려면 README에서 Azure 서비스를 이미 만들었어야 합니다. 이 작업을 완료한 후에는 모든 셀을 실행할 수 있지만 인덱서가 완료되고 검색 인덱스가 로드될 때까지 쿼리에서 결과를 반환하지 않습니다.\n",
        "\n",
        "We recommend running each step and making sure it completes before moving on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![cog-search](./images/Cog-Search-Enrich.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "editable": true,
        "gather": {
          "logged": 1713751202468
        },
        "run_control": {
          "frozen": false
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "# Name of the container in your Blob Storage Datasource ( in credentials.env)\n",
        "BLOB_CONTAINER_NAME = \"hrdocs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1713751202644
        }
      },
      "outputs": [],
      "source": [
        "# Define the names for the data source, skillset, index and indexer\n",
        "datasource_name = \"cogsrch-datasource-hrdocs\"\n",
        "index_name = \"cogsrch-index-hrdocs\"\n",
        "skillset_name = \"cogsrch-skillset-hrdocs\"\n",
        "indexer_name = \"cogsrch-indexer-hrdocs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1713751202839
        }
      },
      "outputs": [],
      "source": [
        "# Setup the Payloads header\n",
        "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
        "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Data Source (Blob container with the Contoso Electronics HR PDFs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1713751203215
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "201\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# The following code sends the json paylod to Azure Search engine to create the Datasource\n",
        "\n",
        "datasource_payload = {\n",
        "    \"name\": datasource_name,\n",
        "    \"description\": \"hr document files to demonstrate AI search capabilities.\",\n",
        "    \"type\": \"azureblob\",\n",
        "    \"credentials\": {\n",
        "        \"connectionString\": os.environ['BLOB_CONNECTION_STRING']\n",
        "    },\n",
        "    \"dataDeletionDetectionPolicy\" : {\n",
        "        \"@odata.type\" :\"#Microsoft.Azure.Search.NativeBlobSoftDeleteDeletionDetectionPolicy\" # this makes sure that if the item is deleted from the source, it will be deleted from the index\n",
        "    },\n",
        "    \"container\": {\n",
        "        \"name\": BLOB_CONTAINER_NAME\n",
        "    }\n",
        "}\n",
        "r = requests.put(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/datasources/\" + datasource_name,\n",
        "                 data=json.dumps(datasource_payload), headers=headers, params=params)\n",
        "print(r.status_code)\n",
        "print(r.ok)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 201 - Successfully created\n",
        "- 204 - Succesfully overwritten\n",
        "- 40X - Authentication Error\n",
        "\n",
        "For information on Change and Delete file detection please see [HERE](https://learn.microsoft.com/en-us/azure/search/search-howto-index-changed-deleted-blobs?tabs=rest-api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713751203397
        }
      },
      "outputs": [],
      "source": [
        "# If you have a 403 code, probably you have a wrong endpoint or key, you can debug by uncomment this\n",
        "# r.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Index"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Azure AI Search에서 검색 인덱스는 검색 엔진에서 인덱싱, 전체 텍스트 검색, 벡터 검색, 하이브리드 검색 및 필터링된 쿼리를 위해 사용할 수 있는 검색 가능한 콘텐츠입니다. 인덱스는 스키마에 의해 정의되고 검색 서비스에 저장되며, 데이터 가져오기는 두 번째 단계로 이어집니다. 이 콘텐츠는 최신 검색 애플리케이션에서 기대되는 밀리초 단위의 응답 시간을 위해 필요한 기본 데이터 저장소와는 별도로 검색 서비스 내에 존재합니다. 인덱서 기반 인덱싱 시나리오를 제외하고 검색 서비스는 소스 데이터에 연결하거나 쿼리하지 않습니다.\n",
        "\n",
        "Reference:\n",
        "\n",
        "https://learn.microsoft.com/en-us/azure/search/search-what-is-an-index"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "아래에서 벡터 저장소를 만드는 방법을 확인하세요. Azure AI Search에서 벡터 저장소에는 벡터 및 비벡터 필드를 정의하는 인덱스 스키마, 임베딩 공간을 만드는 알고리즘에 대한 벡터 구성, 쿼리 요청에 사용되는 벡터 필드 정의에 대한 설정이 있습니다. \n",
        "\n",
        "또한 결과 세트에 대한 의미론적 순위를 설정하여 의미론적으로 가장 관련성이 높은 결과를 스택의 맨 위로 끌어올릴 수 있습니다. 또한 가장 관련성이 높은 용어와 구문, 의미론적 답변에 대한 하이라이트가 포함된 의미론적 캡션을 얻을 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1713751203621
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "201\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Create an index\n",
        "# Queries operate over the searchable fields and filterable fields in the index\n",
        "index_payload = {\n",
        "    \"name\": index_name,\n",
        "    \"vectorSearch\": {\n",
        "        \"algorithms\": [\n",
        "            {\n",
        "                \"name\": \"myalgo\",\n",
        "                \"kind\": \"hnsw\"\n",
        "            }\n",
        "        ],\n",
        "        \"vectorizers\": [\n",
        "            {\n",
        "                \"name\": \"openai\",\n",
        "                \"kind\": \"azureOpenAI\",\n",
        "                \"azureOpenAIParameters\":\n",
        "                {\n",
        "                    \"resourceUri\" : os.environ['AZURE_OPENAI_ENDPOINT'],\n",
        "                    \"apiKey\" : os.environ['AZURE_OPENAI_API_KEY'],\n",
        "                    \"deploymentId\" : os.environ['EMBEDDING_DEPLOYMENT_NAME']\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        \"profiles\": [\n",
        "            {\n",
        "                \"name\": \"myprofile\",\n",
        "                \"algorithm\": \"myalgo\",\n",
        "                \"vectorizer\":\"openai\"\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"semantic\": {\n",
        "        \"configurations\": [\n",
        "            {\n",
        "                \"name\": \"my-semantic-config\",\n",
        "                \"prioritizedFields\": {\n",
        "                    \"titleField\": {\n",
        "                        \"fieldName\": \"title\"\n",
        "                    },\n",
        "                    \"prioritizedContentFields\": [\n",
        "                        {\n",
        "                            \"fieldName\": \"chunk\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"prioritizedKeywordsFields\": []\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"fields\": [\n",
        "        {\"name\": \"id\", \"type\": \"Edm.String\", \"key\": \"true\", \"analyzer\": \"keyword\", \"searchable\": \"true\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\",\"facetable\": \"false\"},\n",
        "        {\"name\": \"ParentKey\", \"type\": \"Edm.String\", \"searchable\": \"true\", \"retrievable\": \"true\", \"facetable\": \"false\", \"filterable\": \"true\", \"sortable\": \"false\"},\n",
        "        {\"name\": \"title\", \"type\": \"Edm.String\", \"searchable\": \"true\", \"retrievable\": \"true\", \"facetable\": \"false\", \"filterable\": \"true\", \"sortable\": \"false\"},\n",
        "        {\"name\": \"name\", \"type\": \"Edm.String\", \"searchable\": \"true\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
        "        {\"name\": \"location\", \"type\": \"Edm.String\", \"searchable\": \"true\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},   \n",
        "        {\"name\": \"chunk\",\"type\": \"Edm.String\", \"searchable\": \"true\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
        "        {\n",
        "            \"name\": \"chunkVector\",\n",
        "            \"type\": \"Collection(Edm.Single)\",\n",
        "            \"dimensions\": 1536, # IMPORTANT: Make sure these dimmensions match your embedding model name\n",
        "            \"vectorSearchProfile\": \"myprofile\",\n",
        "            \"searchable\": \"true\",\n",
        "            \"retrievable\": \"true\",\n",
        "            \"filterable\": \"false\",\n",
        "            \"sortable\": \"false\",\n",
        "            \"facetable\": \"false\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "r = requests.put(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + index_name,\n",
        "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
        "print(r.status_code)\n",
        "print(r.ok)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713751203765
        }
      },
      "outputs": [],
      "source": [
        "r.text"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Semantic Search capabilities\n",
        "\n",
        "위의 인덱스 페이로드에서 볼 수 있듯이 '시맨틱 구성'이 있습니다.\n",
        "\n",
        "시맨틱 랭커는 텍스트 기반 쿼리에 대한 초기 BM25 랭킹 또는 RRF 랭킹 검색 결과의 품질을 개선하는 쿼리 관련 기능 모음입니다. \n",
        "\n",
        "검색 서비스에서 이 기능을 활성화하면 시맨틱 랭킹은 두 가지 방식으로 쿼리 실행 파이프라인을 확장합니다.\n",
        "\n",
        "    첫째, BM25 또는 RRF를 사용하여 채점된 초기 결과 세트에 보조 순위를 추가합니다. 이 보조 순위는 의미론적으로 가장 관련성이 높은 결과를 표시하기 위해 Microsoft Bing에서 채택한 다국어 딥 러닝 모델을 사용합니다.\n",
        "    \n",
        "    둘째, 응답에서 캡션과 답변을 추출하여 반환하며, 이를 검색 페이지에 렌더링하여 사용자의 검색 환경을 개선할 수 있습니다.\n",
        "\n",
        "더 자세한 설명과 제한 사항은 [여기](https://learn.microsoft.com/en-us/azure/search/semantic-ranking)를 참조하세요.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Skillset - OCR, Text Splitter, AzureOpenAIEmbeddingSkill\n",
        "\n",
        "We need to create now the skillset. This is a set of steps in which we use AI Services to enrich the documents by extracting information, applying OCR, splitting, and embedding chunks, among other skills.\n",
        "\n",
        "https://learn.microsoft.com/en-us/azure/search/cognitive-search-working-with-skillsets\n",
        "\n",
        "https://learn.microsoft.com/en-us/azure/search/cognitive-search-predefined-skills\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "아래에서 인덱스 투영을 사용하고 있음을 알 수 있습니다. 기본적으로 스킬셋 내에서 처리된 하나의 문서는 검색 인덱스의 단일 문서에 매핑됩니다. 즉, 입력 텍스트의 청킹을 수행한 다음 각 청크에 대해 보강을 수행하면 출력 필드 매핑을 통해 매핑된 인덱스의 결과는 생성된 보강의 배열이 됩니다. **인덱스 투영을 사용하면 각 강화 데이터 청크를 자체 검색 문서에 매핑할 컨텍스트를 정의할 수 있습니다**. 이를 통해 문서의 보강된 데이터를 검색 인덱스에 일대다 매핑할 수 있습니다.\n",
        "    \n",
        "매개변수: `\"projectionMode\": \"skipIndexingParentDocuments\"`를 사용하면 상위 문서의 인덱싱을 건너뛰고 청크와 그 벡터가 포함된 인덱스만 유지할 수 있습니다.\n",
        "\n",
        "### Content Lifecycle\n",
        "인덱서 데이터 소스가 변경 추적 및 삭제 감지를 지원하는 경우, 인덱싱 프로세스는 기본 색인(부모 문서)과 보조 색인(청크)을 동기화하여 이러한 변경 사항을 포착할 수 있습니다.\n",
        "\n",
        "\n",
        "인덱서 및 스킬셋을 실행할 때마다 스킬셋 또는 기본 소스 데이터가 변경되면 인덱스 예상이 업데이트됩니다. 색인기가 포착한 모든 변경 사항은 보강 프로세스를 통해 인덱스의 투영으로 전파되어 투영 데이터가 원본 데이터 소스의 콘텐츠를 최신으로 표현하도록 보장합니다. 이렇게 하면 몇 주에 걸친 프로그래밍과 콘텐츠를 동기화하기 위한 많은 골칫거리를 줄일 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1713751203907
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "201\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Create a skillset\n",
        "skillset_payload = {\n",
        "    \"name\": skillset_name,\n",
        "    \"description\": \"e2e Skillset for RAG - Files\",\n",
        "    \"skills\":\n",
        "    [\n",
        "        {\n",
        "            \"@odata.type\": \"#Microsoft.Skills.Vision.OcrSkill\",\n",
        "            \"description\": \"Extract text (plain and structured) from image.\",\n",
        "            \"context\": \"/document/normalized_images/*\",\n",
        "            \"defaultLanguageCode\": \"en\",\n",
        "            \"detectOrientation\": True,\n",
        "            \"inputs\": [\n",
        "                {\n",
        "                  \"name\": \"image\",\n",
        "                  \"source\": \"/document/normalized_images/*\"\n",
        "                }\n",
        "            ],\n",
        "                \"outputs\": [\n",
        "                {\n",
        "                  \"name\": \"text\",\n",
        "                  \"targetName\" : \"images_text\"\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"@odata.type\": \"#Microsoft.Skills.Text.MergeSkill\",\n",
        "            \"description\": \"Create merged_text, which includes all the textual representation of each image inserted at the right location in the content field. This is useful for PDF and other file formats that supported embedded images.\",\n",
        "            \"context\": \"/document\",\n",
        "            \"insertPreTag\": \" \",\n",
        "            \"insertPostTag\": \" \",\n",
        "            \"inputs\": [\n",
        "                {\n",
        "                  \"name\":\"text\", \"source\": \"/document/content\"\n",
        "                },\n",
        "                {\n",
        "                  \"name\": \"itemsToInsert\", \"source\": \"/document/normalized_images/*/images_text\"\n",
        "                },\n",
        "                {\n",
        "                  \"name\":\"offsets\", \"source\": \"/document/normalized_images/*/contentOffset\"\n",
        "                }\n",
        "            ],\n",
        "            \"outputs\": [\n",
        "                {\n",
        "                  \"name\": \"mergedText\", \n",
        "                  \"targetName\" : \"merged_text\"\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"@odata.type\": \"#Microsoft.Skills.Text.SplitSkill\",\n",
        "            \"context\": \"/document\",\n",
        "            \"textSplitMode\": \"pages\",  # although it says \"pages\" it actally means chunks, not actual pages\n",
        "            \"maximumPageLength\": 5000, # 5000 characters is default and a good choice\n",
        "            \"pageOverlapLength\": 750,  # 15% overlap among chunks\n",
        "            \"defaultLanguageCode\": \"en\",\n",
        "            \"inputs\": [\n",
        "                {\n",
        "                    \"name\": \"text\",\n",
        "                    \"source\": \"/document/merged_text\"\n",
        "                }\n",
        "            ],\n",
        "            \"outputs\": [\n",
        "                {\n",
        "                    \"name\": \"textItems\",\n",
        "                    \"targetName\": \"chunks\"\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"@odata.type\": \"#Microsoft.Skills.Text.AzureOpenAIEmbeddingSkill\",\n",
        "            \"description\": \"Azure OpenAI Embedding Skill\",\n",
        "            \"context\": \"/document/chunks/*\",\n",
        "            \"resourceUri\": os.environ['AZURE_OPENAI_ENDPOINT'],\n",
        "            \"apiKey\": os.environ['AZURE_OPENAI_API_KEY'],\n",
        "            \"deploymentId\": os.environ['EMBEDDING_DEPLOYMENT_NAME'],\n",
        "            \"inputs\": [\n",
        "                {\n",
        "                    \"name\": \"text\",\n",
        "                    \"source\": \"/document/chunks/*\"\n",
        "                }\n",
        "            ],\n",
        "            \"outputs\": [\n",
        "                {\n",
        "                    \"name\": \"embedding\",\n",
        "                    \"targetName\": \"vector\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        "    \"indexProjections\": {\n",
        "        \"selectors\": [\n",
        "            {\n",
        "                \"targetIndexName\": index_name,\n",
        "                \"parentKeyFieldName\": \"ParentKey\",\n",
        "                \"sourceContext\": \"/document/chunks/*\",\n",
        "                \"mappings\": [\n",
        "                    {\n",
        "                        \"name\": \"title\",\n",
        "                        \"source\": \"/document/title\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": \"name\",\n",
        "                        \"source\": \"/document/name\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": \"location\",\n",
        "                        \"source\": \"/document/location\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": \"chunk\",\n",
        "                        \"source\": \"/document/chunks/*\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"name\": \"chunkVector\",\n",
        "                        \"source\": \"/document/chunks/*/vector\"\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"parameters\": {\n",
        "            \"projectionMode\": \"skipIndexingParentDocuments\"\n",
        "        }\n",
        "    },\n",
        "    \"cognitiveServices\": {\n",
        "        \"@odata.type\": \"#Microsoft.Azure.Search.CognitiveServicesByKey\",\n",
        "        \"description\": os.environ['COG_SERVICES_NAME'],\n",
        "        \"key\": os.environ['COG_SERVICES_KEY']\n",
        "    }\n",
        "}\n",
        "\n",
        "r = requests.put(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/skillsets/\" + skillset_name,\n",
        "                 data=json.dumps(skillset_payload), headers=headers, params=params)\n",
        "print(r.status_code)\n",
        "print(r.ok)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713751204066
        }
      },
      "outputs": [],
      "source": [
        "print(r.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create and Run the Indexer - (runs the pipeline)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "지금까지 만든 세 가지 구성 요소(데이터 원본, 스킬셋, 인덱스)는 인덱서에 대한 입력입니다. Azure Cognitive Search에서 인덱서를 만드는 것이 전체 파이프라인을 작동시키는 이벤트입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1713751204247
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "201\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Create an indexer\n",
        "indexer_payload = {\n",
        "    \"name\": indexer_name,\n",
        "    \"dataSourceName\": datasource_name,\n",
        "    \"targetIndexName\": index_name,\n",
        "    \"skillsetName\": skillset_name,\n",
        "    \"disabled\": None,\n",
        "    \"schedule\" : None, # How often do you want to check for new content in the data source\n",
        "    \"fieldMappings\": [\n",
        "        {\n",
        "          \"sourceFieldName\" : \"metadata_storage_name\",\n",
        "          \"targetFieldName\" : \"title\"\n",
        "        },\n",
        "        {\n",
        "          \"sourceFieldName\" : \"metadata_storage_name\",\n",
        "          \"targetFieldName\" : \"name\"\n",
        "        },        \n",
        "        {\n",
        "          \"sourceFieldName\" : \"metadata_storage_path\",\n",
        "          \"targetFieldName\" : \"location\"\n",
        "        }        \n",
        "    ],\n",
        "    \"outputFieldMappings\":[],\n",
        "    \"parameters\":\n",
        "    {\n",
        "        \"maxFailedItems\": -1,\n",
        "        \"maxFailedItemsPerBatch\": -1,\n",
        "        \"configuration\":\n",
        "        {\n",
        "            \"dataToExtract\": \"contentAndMetadata\",\n",
        "            \"imageAction\": \"generateNormalizedImages\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "r = requests.put(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexers/\" + indexer_name,\n",
        "                 data=json.dumps(indexer_payload), headers=headers, params=params)\n",
        "print(r.status_code)\n",
        "print(r.ok)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713751204370
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment if you find an error\n",
        "r.text"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note : 400 권한 없음 오류가 발생하는 경우, 쿼리 키가 아닌 Azure Search 관리 키를 사용하고 있는지 확인하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1713751204527
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n",
            "Status: inProgress\n",
            "Items Processed: 0\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Optionally, get indexer status to confirm that it's running\n",
        "try:\n",
        "    r = requests.get(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexers/\" + indexer_name +\n",
        "                     \"/status\", headers=headers, params=params)\n",
        "    # pprint(json.dumps(r.json(), indent=1))\n",
        "    print(r.status_code)\n",
        "    print(\"Status:\",r.json().get('lastResult').get('status'))\n",
        "    print(\"Items Processed:\",r.json().get('lastResult').get('itemsProcessed'))\n",
        "    print(r.ok)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(\"Wait a few seconds until the process starts and run this cell again.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**실행된 인덱스를 Azure Portal에서 확인합니다.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# References\n",
        "\n",
        "- https://learn.microsoft.com/en-us/azure/search/cognitive-search-tutorial-blob\n",
        "- https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/search\n",
        "- https://learn.microsoft.com/en-us/azure/search/search-get-started-vector"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NEXT\n",
        "이제 인덱스가 로드되었으므로 다음 노트북 3에서는 인덱스 쿼리를 수행하고 Azure AI Search의 재랭커 시맨틱 점수를 기반으로 결과를 정렬한 다음 OpenAI를 사용하여 결과를 이해하고 가능한 최상의 답변을 제공하겠습니다."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

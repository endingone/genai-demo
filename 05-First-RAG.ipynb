{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "76fbaf88-5952-47bf-a68c-85011e49b6de",
      "metadata": {},
      "source": [
        "# Building our First RAG bot - Skill: talk to Search Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "967c3b06-c8a0-45db-be9a-974c762ba4b8",
      "metadata": {},
      "source": [
        "이제 '내 데이터와 대화'하는 첫 번째 봇을 구축하기 위한 모든 구성 요소를 갖추었습니다. 이 블록은 다음과 같습니다. \n",
        "\n",
        "1) 내 데이터를 청크 단위로 잘 인덱싱된 하이브리드(텍스트 및 벡터) 엔진 -> Azure AI Search\n",
        "2) LLM 앱 빌드를 위한 좋은 LLM 파이썬 프레임워크 -> LangChain\n",
        "3) 언어를 이해하고 지침을 따르는 고품질 OpenAI GPT 모델 -> GPT3.5 and GPT4\n",
        "4) 영구 메모리 데이터베이스 -> CosmosDB\n",
        "\n",
        "한 가지 놓친 것이 있습니다. **Agents**.\n",
        "\n",
        "이 노트북에서는 에이전트의 개념을 소개하고 이를 사용하여 RAG 봇을 구축해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b64f701d-5b9d-4c7c-b259-c2a515c75961",
      "metadata": {
        "gather": {
          "logged": 1713624044568
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import asyncio\n",
        "from typing import Dict, List\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from typing import Optional, Type\n",
        "\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.runnables import ConfigurableField, ConfigurableFieldSpec\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory, CosmosDBChatMessageHistory\n",
        "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import BaseTool, StructuredTool, tool\n",
        "\n",
        "#custom libraries that we will use later in the app\n",
        "from common.utils import  GetDocSearchResults_Tool\n",
        "from common.prompts import AGENT_DOCSEARCH_PROMPT\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4163af7-39d0-43b4-8dad-c13108d22a1d",
      "metadata": {
        "gather": {
          "logged": 1713624044857
        }
      },
      "outputs": [],
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33836104-822e-4846-8b81-0de8e24838f1",
      "metadata": {},
      "source": [
        "## Introducing: Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16fc3d38-93f8-4a47-8125-d1bb9f529178",
      "metadata": {},
      "source": [
        "에이전트의 구현은 [MRKL 시스템](https://arxiv.org/abs/2205.00445) 논문('기적'이라는 뜻 😉)과 [ReAct](https://arxiv.org/abs/2210.03629) 논문에서 영감을 얻었습니다.\n",
        "\n",
        "에이전트는 프롬프트를 이해하고 그에 따라 행동하는 LLM의 능력을 활용할 수 있는 방법입니다. 본질적으로 에이전트는 매우 영리한 최초 프롬프트가 주어진 LLM입니다. 프롬프트는 복잡한 쿼리에 대한 답변 프로세스를 한 번에 하나씩 해결되는 일련의 단계로 세분화하도록 LLM에 지시합니다.\n",
        "\n",
        "에이전트는 MRKL 백서에서 소개한 '전문가'와 결합하면 정말 멋진 존재가 됩니다. 간단한 예로 에이전트 자체로는 수학적 계산을 안정적으로 수행할 수 있는 고유한 기능이 없을 수 있습니다. 하지만 이 경우 수학적 계산에 능숙한 전문가인 계산기를 도입할 수 있습니다. 이제 계산을 수행해야 할 때 에이전트는 결과 자체를 예측하는 대신 전문가를 호출할 수 있습니다. 이것이 바로 [ChatGPT 플러그인](https://openai.com/blog/chatgpt-plugins)의 개념입니다.\n",
        "\n",
        "우리의 경우 \"데이터와 대화하는 스마트 봇을 어떻게 구축할 것인가\"라는 문제를 해결하기 위해서는 특정 데이터 소스를 읽거나 로드하거나 이해하거나 상호 작용하기 위해 '전문가/도구'를 사용해야 한다는 것을 LLM에 지시하는 REACT/MRKL 접근 방식이 필요합니다.\n",
        "\n",
        "그런 다음 사용자와 상호 작용하고 도구를 사용하여 검색 엔진에서 정보를 가져오는 에이전트를 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7999a06-aff0-4d21-8be7-fe56c70082a8",
      "metadata": {},
      "source": [
        "#### We start first defining the Tool/Expert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a862366b-ce9e-44f8-9610-84ec568653ea",
      "metadata": {
        "gather": {
          "logged": 1713624045087
        }
      },
      "outputs": [],
      "source": [
        "index_name = \"cogsrch-index-hrdocs\"\n",
        "indexes = [index_name]\n",
        "\n",
        "tool_for_hrdocs = GetDocSearchResults_Tool(description=\"It is useful for searching HR information about policies of company\", indexes=indexes, k=5, reranker_th=1, sas_token=os.environ['BLOB_SAS_TOKEN'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "180550e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "index_name = \"cogsrch-index-techdocs\"\n",
        "indexes = [index_name]\n",
        "\n",
        "tool_for_techdocs = GetDocSearchResults_Tool(description=\"It is useful for searching technical information about Azure Services\", indexes=indexes, k=5, reranker_th=1, sas_token=os.environ['BLOB_SAS_TOKEN'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "077886c8-c5d0-481d-a5f9-f4becf60e0f9",
      "metadata": {},
      "source": [
        "리트리버 객체를 도구 객체(\"전문가\")로 변환해야 합니다. `utils.py`에서 `GetDocSearchResults_Tool` 도구를 확인하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f73c6ca7-d93b-4961-b90a-08572cad78d8",
      "metadata": {},
      "source": [
        "Declare the tools the agent will use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a0fd3a0-527c-42e3-a092-46e03d33bd07",
      "metadata": {
        "gather": {
          "logged": 1713624045276
        }
      },
      "outputs": [],
      "source": [
        "tools = [tool_for_hrdocs, tool_for_techdocs]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9cac295-8be5-4803-8342-6d4e48cd2294",
      "metadata": {},
      "source": [
        "Get the prompt to use `AGENT_DOCSEARCH_PROMPT` - you can modify this in `prompts.py`! Check it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44f8df6-a68e-4215-99f3-10119f796c0c",
      "metadata": {
        "gather": {
          "logged": 1713624045468
        }
      },
      "outputs": [],
      "source": [
        "prompt = AGENT_DOCSEARCH_PROMPT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f3ddf18-3f3c-44b4-8af5-1437973da010",
      "metadata": {},
      "source": [
        "Define the LLM to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aaaf7f5-ef26-48d8-868d-b53aa4c4f9f4",
      "metadata": {
        "gather": {
          "logged": 1713624045688
        }
      },
      "outputs": [],
      "source": [
        "COMPLETION_TOKENS = 1500\n",
        "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True).configurable_alternatives(\n",
        "    ConfigurableField(id=\"model\"),\n",
        "    default_key=\"gpt35\",\n",
        "    gpt4=AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d527c12-4e18-4f3f-a9ec-8dab4f9ca7b2",
      "metadata": {},
      "source": [
        "Construct the OpenAI Tools agent.\n",
        "> OpenAI API has deprecated functions in favor of tools. The difference between the two is that the tools API allows the model to request that multiple functions be invoked at once, which can reduce response times in some architectures. It’s recommended to use the tools agent for OpenAI models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fff2766-defb-45fc-b271-3c811077076b",
      "metadata": {
        "gather": {
          "logged": 1713624045950
        }
      },
      "outputs": [],
      "source": [
        "agent = create_openai_tools_agent(llm.with_config(configurable={\"model\": \"gpt35\"}), tools, prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "338336d9-a64a-4602-908a-742b418e4520",
      "metadata": {},
      "source": [
        "Create an agent executor by passing in the agent and tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad6c156f-9a17-4daa-80de-70ce2f55063b",
      "metadata": {
        "gather": {
          "logged": 1713624046154
        }
      },
      "outputs": [],
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252a017c-3b36-43ab-8633-78f4f005d166",
      "metadata": {},
      "source": [
        "Give it memory - since AgentExecutor is also a Runnable class, we do the same with did on Notebook 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c013314-afe6-4218-b179-d0f7312d2670",
      "metadata": {
        "gather": {
          "logged": 1713624046357
        }
      },
      "outputs": [],
      "source": [
        "def get_session_history(session_id: str, user_id: str) -> CosmosDBChatMessageHistory:\n",
        "    cosmos = CosmosDBChatMessageHistory(\n",
        "        cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
        "        cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
        "        cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
        "        connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
        "        session_id=session_id,\n",
        "        user_id=user_id\n",
        "        )\n",
        "\n",
        "    # prepare the cosmosdb instance\n",
        "    cosmos.prepare_cosmos()\n",
        "    return cosmos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13df017f-3ab7-4943-adc1-3477badf3d3e",
      "metadata": {},
      "source": [
        "CosmosDB에는 두 개의 필드(id와 파티션)가 필요하고, RunnableWithMessageHistory는 기본적으로 하나의 메모리 식별자(session_id)만 사용하므로 `history_factory_config` 파라미터를 사용하고 메모리 클래스에 대한 여러 키를 정의해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf93758f-da3b-48fb-9882-91fe327b1751",
      "metadata": {
        "gather": {
          "logged": 1713624046587
        }
      },
      "outputs": [],
      "source": [
        "userid_spec = ConfigurableFieldSpec(\n",
        "            id=\"user_id\",\n",
        "            annotation=str,\n",
        "            name=\"User ID\",\n",
        "            description=\"Unique identifier for the user.\",\n",
        "            default=\"\",\n",
        "            is_shared=True,\n",
        "        )\n",
        "session_id = ConfigurableFieldSpec(\n",
        "            id=\"session_id\",\n",
        "            annotation=str,\n",
        "            name=\"Session ID\",\n",
        "            description=\"Unique identifier for the conversation.\",\n",
        "            default=\"\",\n",
        "            is_shared=True,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d1aaa6-efca-4512-b680-896dae39a359",
      "metadata": {
        "gather": {
          "logged": 1713624046791
        }
      },
      "outputs": [],
      "source": [
        "agent_with_chat_history = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"question\",\n",
        "    history_messages_key=\"history\",\n",
        "    history_factory_config=[userid_spec,session_id]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c6b489-3db9-4965-9eae-ed2790e62bd7",
      "metadata": {
        "gather": {
          "logged": 1713624047055
        }
      },
      "outputs": [],
      "source": [
        "# configure the session id and user id\n",
        "random_session_id = \"session\"+ str(random.randint(1, 1000))\n",
        "ramdom_user_id = \"user\"+ str(random.randint(1, 1000))\n",
        "\n",
        "config={\"configurable\": {\"session_id\": random_session_id, \"user_id\": ramdom_user_id}}\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3295c54e-a5e2-46f6-99fc-6f76453a877d",
      "metadata": {},
      "source": [
        "Run the Agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac81763-6bcc-4408-9daf-d047a0e2cb08",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "agent_with_chat_history.invoke({\"question\": \"Hi, I'm Pablo Marin. What's yours\"}, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb3fca7e-33a1-40f1-afb0-dee441a1d1d5",
      "metadata": {
        "gather": {
          "logged": 1713624050152
        }
      },
      "outputs": [],
      "source": [
        "printmd(agent_with_chat_history.invoke(\n",
        "    {\"question\": \"Can I restore my index or service once it's deleted?\"}, \n",
        "    config=config)[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c430c456-f390-4319-a3b1-bee19da130cf",
      "metadata": {
        "gather": {
          "logged": 1713624056642
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    printmd(agent_with_chat_history.invoke(\n",
        "        {\"question\": \"Interesting, Can I move, backup, and restore indexes?\"},\n",
        "        config=config)[\"output\"])\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd54f71-03c9-4332-885b-0d1df942fa88",
      "metadata": {
        "gather": {
          "logged": 1713624058514
        }
      },
      "outputs": [],
      "source": [
        "printmd(agent_with_chat_history.invoke({\"question\": \"Thhank you!\"}, config=config)[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "149648ba-945d-4e7d-81f7-a8bca2ac87f2",
      "metadata": {},
      "source": [
        "#### Important: GPT3.5에는 긴 프롬프트와 긴 문맥, 상세한 답변을 추가하기 시작하거나 상담원이 여러 단계의 질문을 여러 번 검색하면 공간이 부족하다는 한계가 있습니다!\n",
        "\n",
        "몇가지 방법으로 이 문제를 해소할 수는 있습니다. \n",
        "- 더 짧은 System 프롬프트\n",
        "- 청크를 더 작게(기본값인 5000자 미만으로)\n",
        "- 관련성이 낮은 청크를 가져오기 위해 topK 줄이기\n",
        "\n",
        "그러나 궁극적으로 모든 것을 GPT3.5(더 저렴하고 빠른 모델)로 작동시키기 위해 품질을 포기해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41787714-73fd-4336-85f2-bec3abb41eda",
      "metadata": {},
      "source": [
        "### Let's add more things we have learned so far: dynamic LLM selection of GPT4 and asyncronous streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1511d2c3-97fe-4232-a560-014d0f157008",
      "metadata": {
        "gather": {
          "logged": 1713624058777
        }
      },
      "outputs": [],
      "source": [
        "agent = create_openai_tools_agent(llm.with_config(configurable={\"model\": \"gpt4\"}), tools, prompt) # We select now GPT-4\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
        "agent_with_chat_history = RunnableWithMessageHistory(agent_executor,get_session_history,input_messages_key=\"question\", \n",
        "                                                     history_messages_key=\"history\", history_factory_config=[userid_spec,session_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bec5b32-6017-44b9-97e7-34ba3695e688",
      "metadata": {},
      "source": [
        "이전 노트북에서는 토큰을 스트리밍하기 위해 실행 가능 함수의 `.stream()` 함수를 사용했습니다.  However if you need to stream individual tokens from the agent or surface steps occuring within tools, you would need to use a combination of `Callbacks` and `.astream()` OR the new `astream_events` API (beta).\n",
        "\n",
        "여기서는 astream_events API를 사용하여 다음 이벤트를 스트리밍해 보겠습니다.\n",
        "\n",
        "    Agent Start with inputs\n",
        "    Tool Start with inputs\n",
        "    Tool End with outputs\n",
        "    Stream the agent final anwer token by token\n",
        "    Agent End with outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9600a35e-8d2e-43d0-a334-092b2e8b832c",
      "metadata": {
        "gather": {
          "logged": 1713624058976
        }
      },
      "outputs": [],
      "source": [
        "QUESTION = \"Tell me more about your last answer, search again multiple times and provide a deeper explanation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3808fa33-05bb-4f5d-9ab9-7159f6db62a8",
      "metadata": {
        "gather": {
          "logged": 1713624205700
        }
      },
      "outputs": [],
      "source": [
        "async for event in agent_with_chat_history.astream_events(\n",
        "    {\"question\": QUESTION}, config=config, version=\"v1\",\n",
        "):\n",
        "    kind = event[\"event\"]\n",
        "    if kind == \"on_chain_start\":\n",
        "        if (\n",
        "            event[\"name\"] == \"AgentExecutor\"\n",
        "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
        "            print(\n",
        "                f\"Starting agent: {event['name']}\"\n",
        "            )\n",
        "    elif kind == \"on_chain_end\":\n",
        "        if (\n",
        "            event[\"name\"] == \"AgentExecutor\"\n",
        "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
        "            print()\n",
        "            print(\"--\")\n",
        "            print(\n",
        "                f\"Done agent: {event['name']}\"\n",
        "            )\n",
        "    if kind == \"on_chat_model_stream\":\n",
        "        content = event[\"data\"][\"chunk\"].content\n",
        "        if content:\n",
        "            # Empty content in the context of OpenAI means\n",
        "            # that the model is asking for a tool to be invoked.\n",
        "            # So we only print non-empty content\n",
        "            print(content, end=\"\")\n",
        "    elif kind == \"on_tool_start\":\n",
        "        print(\"--\")\n",
        "        print(\n",
        "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
        "        )\n",
        "    elif kind == \"on_tool_end\":\n",
        "        print(f\"Done tool: {event['name']}\")\n",
        "        # print(f\"Tool output was: {event['data'].get('output')}\")\n",
        "        print(\"--\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b41bba7-18df-4ab8-b4f6-60368160d348",
      "metadata": {},
      "source": [
        "#### Note: 이 마지막 질문을 GPT3.5로 실행하여 LLM의 토큰 공간이 어떻게 부족해지는지 확인해 보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0ec64bf-fe24-42fc-8dde-4d478f0af21e",
      "metadata": {},
      "source": [
        "# Summary\n",
        "\n",
        "We just built our first RAG BOT!.\n",
        "\n",
        "-  봇을 구축하는 가장 좋은 방법은 **에이전트 + 도구**라는 것을 알게 되었습니다. <br>\n",
        "- `utils.py`의 `GetDocSearchResults_Tool` 함수를 사용하여 Azure Search 리트리버(검색기)를 도구로 변환했습니다.\n",
        "- 상담원으로부터 답변을 스트리밍하는 한 가지 방법인 이벤트 API(베타)에 대해 알게 되었습니다.\n",
        "- 포괄적이고 양질의 답변을 제공하기 위해서는 GPT3.5로는 공간이 부족하다는 사실을 알게 되었습니다. 결국 GPT4가 필요하게 됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56306506-d53d-4d43-93e2-a9300ed2a3ee",
      "metadata": {},
      "source": [
        "# NEXT\n",
        "이제 하나의 스킬(문서 검색)을 가진 봇이 생겼으니 더 많은 스킬을 만들어 봅시다! \n",
        "\n",
        "다음 노트북에서는 모든 기능을 하나로 묶는 방법에 대해 안내해 드리겠습니다. \n",
        "\n",
        "모든 노트북의 기능을 어떻게 활용하고 그에 따라 어떤 요청에도 응답할 수 있는 두뇌 에이전트를 만들 수 있을까요?"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

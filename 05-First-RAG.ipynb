{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "76fbaf88-5952-47bf-a68c-85011e49b6de",
      "metadata": {},
      "source": [
        "# Building our First RAG bot - Skill: talk to Search Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "967c3b06-c8a0-45db-be9a-974c762ba4b8",
      "metadata": {},
      "source": [
        "ì´ì œ 'ë‚´ ë°ì´í„°ì™€ ëŒ€í™”'í•˜ëŠ” ì²« ë²ˆì§¸ ë´‡ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ê°–ì¶”ì—ˆìŠµë‹ˆë‹¤. ì´ ë¸”ë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. \n",
        "\n",
        "1) ë‚´ ë°ì´í„°ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ì˜ ì¸ë±ì‹±ëœ í•˜ì´ë¸Œë¦¬ë“œ(í…ìŠ¤íŠ¸ ë° ë²¡í„°) ì—”ì§„ -> Azure AI Search\n",
        "2) LLM ì•± ë¹Œë“œë¥¼ ìœ„í•œ ì¢‹ì€ LLM íŒŒì´ì¬ í”„ë ˆì„ì›Œí¬ -> LangChain\n",
        "3) ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ì§€ì¹¨ì„ ë”°ë¥´ëŠ” ê³ í’ˆì§ˆ OpenAI GPT ëª¨ë¸ -> GPT3.5 and GPT4\n",
        "4) ì˜êµ¬ ë©”ëª¨ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ -> CosmosDB\n",
        "\n",
        "í•œ ê°€ì§€ ë†“ì¹œ ê²ƒì´ ìˆìŠµë‹ˆë‹¤. **Agents**.\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì—ì´ì „íŠ¸ì˜ ê°œë…ì„ ì†Œê°œí•˜ê³  ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ RAG ë´‡ì„ êµ¬ì¶•í•´ë´…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b64f701d-5b9d-4c7c-b259-c2a515c75961",
      "metadata": {
        "gather": {
          "logged": 1713624044568
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import asyncio\n",
        "from typing import Dict, List\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from typing import Optional, Type\n",
        "\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.runnables import ConfigurableField, ConfigurableFieldSpec\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory, CosmosDBChatMessageHistory\n",
        "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from langchain.tools import BaseTool, StructuredTool, tool\n",
        "\n",
        "#custom libraries that we will use later in the app\n",
        "from common.utils import  GetDocSearchResults_Tool\n",
        "from common.prompts import AGENT_DOCSEARCH_PROMPT\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4163af7-39d0-43b4-8dad-c13108d22a1d",
      "metadata": {
        "gather": {
          "logged": 1713624044857
        }
      },
      "outputs": [],
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33836104-822e-4846-8b81-0de8e24838f1",
      "metadata": {},
      "source": [
        "## Introducing: Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16fc3d38-93f8-4a47-8125-d1bb9f529178",
      "metadata": {},
      "source": [
        "ì—ì´ì „íŠ¸ì˜ êµ¬í˜„ì€ [MRKL ì‹œìŠ¤í…œ](https://arxiv.org/abs/2205.00445) ë…¼ë¬¸('ê¸°ì 'ì´ë¼ëŠ” ëœ» ğŸ˜‰)ê³¼ [ReAct](https://arxiv.org/abs/2210.03629) ë…¼ë¬¸ì—ì„œ ì˜ê°ì„ ì–»ì—ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì—ì´ì „íŠ¸ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì´í•´í•˜ê³  ê·¸ì— ë”°ë¼ í–‰ë™í•˜ëŠ” LLMì˜ ëŠ¥ë ¥ì„ í™œìš©í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ë³¸ì§ˆì ìœ¼ë¡œ ì—ì´ì „íŠ¸ëŠ” ë§¤ìš° ì˜ë¦¬í•œ ìµœì´ˆ í”„ë¡¬í”„íŠ¸ê°€ ì£¼ì–´ì§„ LLMì…ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ëŠ” ë³µì¡í•œ ì¿¼ë¦¬ì— ëŒ€í•œ ë‹µë³€ í”„ë¡œì„¸ìŠ¤ë¥¼ í•œ ë²ˆì— í•˜ë‚˜ì”© í•´ê²°ë˜ëŠ” ì¼ë ¨ì˜ ë‹¨ê³„ë¡œ ì„¸ë¶„í™”í•˜ë„ë¡ LLMì— ì§€ì‹œí•©ë‹ˆë‹¤.\n",
        "\n",
        "ì—ì´ì „íŠ¸ëŠ” MRKL ë°±ì„œì—ì„œ ì†Œê°œí•œ 'ì „ë¬¸ê°€'ì™€ ê²°í•©í•˜ë©´ ì •ë§ ë©‹ì§„ ì¡´ì¬ê°€ ë©ë‹ˆë‹¤. ê°„ë‹¨í•œ ì˜ˆë¡œ ì—ì´ì „íŠ¸ ìì²´ë¡œëŠ” ìˆ˜í•™ì  ê³„ì‚°ì„ ì•ˆì •ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ê³ ìœ í•œ ê¸°ëŠ¥ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ê²½ìš° ìˆ˜í•™ì  ê³„ì‚°ì— ëŠ¥ìˆ™í•œ ì „ë¬¸ê°€ì¸ ê³„ì‚°ê¸°ë¥¼ ë„ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ì œ ê³„ì‚°ì„ ìˆ˜í–‰í•´ì•¼ í•  ë•Œ ì—ì´ì „íŠ¸ëŠ” ê²°ê³¼ ìì²´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëŒ€ì‹  ì „ë¬¸ê°€ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì´ ë°”ë¡œ [ChatGPT í”ŒëŸ¬ê·¸ì¸](https://openai.com/blog/chatgpt-plugins)ì˜ ê°œë…ì…ë‹ˆë‹¤.\n",
        "\n",
        "ìš°ë¦¬ì˜ ê²½ìš° \"ë°ì´í„°ì™€ ëŒ€í™”í•˜ëŠ” ìŠ¤ë§ˆíŠ¸ ë´‡ì„ ì–´ë–»ê²Œ êµ¬ì¶•í•  ê²ƒì¸ê°€\"ë¼ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œëŠ” íŠ¹ì • ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì½ê±°ë‚˜ ë¡œë“œí•˜ê±°ë‚˜ ì´í•´í•˜ê±°ë‚˜ ìƒí˜¸ ì‘ìš©í•˜ê¸° ìœ„í•´ 'ì „ë¬¸ê°€/ë„êµ¬'ë¥¼ ì‚¬ìš©í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì„ LLMì— ì§€ì‹œí•˜ëŠ” REACT/MRKL ì ‘ê·¼ ë°©ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
        "\n",
        "ê·¸ëŸ° ë‹¤ìŒ ì‚¬ìš©ìì™€ ìƒí˜¸ ì‘ìš©í•˜ê³  ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ì—”ì§„ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7999a06-aff0-4d21-8be7-fe56c70082a8",
      "metadata": {},
      "source": [
        "#### We start first defining the Tool/Expert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a862366b-ce9e-44f8-9610-84ec568653ea",
      "metadata": {
        "gather": {
          "logged": 1713624045087
        }
      },
      "outputs": [],
      "source": [
        "index_name = \"cogsrch-index-hrdocs\"\n",
        "indexes = [index_name]\n",
        "\n",
        "tool_for_hrdocs = GetDocSearchResults_Tool(description=\"It is useful for searching HR information about policies of company\", indexes=indexes, k=5, reranker_th=1, sas_token=os.environ['BLOB_SAS_TOKEN'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "180550e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "index_name = \"cogsrch-index-techdocs\"\n",
        "indexes = [index_name]\n",
        "\n",
        "tool_for_techdocs = GetDocSearchResults_Tool(description=\"It is useful for searching technical information about Azure Services\", indexes=indexes, k=5, reranker_th=1, sas_token=os.environ['BLOB_SAS_TOKEN'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "077886c8-c5d0-481d-a5f9-f4becf60e0f9",
      "metadata": {},
      "source": [
        "ë¦¬íŠ¸ë¦¬ë²„ ê°ì²´ë¥¼ ë„êµ¬ ê°ì²´(\"ì „ë¬¸ê°€\")ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤. `utils.py`ì—ì„œ `GetDocSearchResults_Tool` ë„êµ¬ë¥¼ í™•ì¸í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f73c6ca7-d93b-4961-b90a-08572cad78d8",
      "metadata": {},
      "source": [
        "Declare the tools the agent will use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a0fd3a0-527c-42e3-a092-46e03d33bd07",
      "metadata": {
        "gather": {
          "logged": 1713624045276
        }
      },
      "outputs": [],
      "source": [
        "tools = [tool_for_hrdocs, tool_for_techdocs]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9cac295-8be5-4803-8342-6d4e48cd2294",
      "metadata": {},
      "source": [
        "Get the prompt to use `AGENT_DOCSEARCH_PROMPT` - you can modify this in `prompts.py`! Check it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44f8df6-a68e-4215-99f3-10119f796c0c",
      "metadata": {
        "gather": {
          "logged": 1713624045468
        }
      },
      "outputs": [],
      "source": [
        "prompt = AGENT_DOCSEARCH_PROMPT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f3ddf18-3f3c-44b4-8af5-1437973da010",
      "metadata": {},
      "source": [
        "Define the LLM to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aaaf7f5-ef26-48d8-868d-b53aa4c4f9f4",
      "metadata": {
        "gather": {
          "logged": 1713624045688
        }
      },
      "outputs": [],
      "source": [
        "COMPLETION_TOKENS = 1500\n",
        "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True).configurable_alternatives(\n",
        "    ConfigurableField(id=\"model\"),\n",
        "    default_key=\"gpt35\",\n",
        "    gpt4=AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d527c12-4e18-4f3f-a9ec-8dab4f9ca7b2",
      "metadata": {},
      "source": [
        "Construct the OpenAI Tools agent.\n",
        "> OpenAI API has deprecated functions in favor of tools. The difference between the two is that the tools API allows the model to request that multiple functions be invoked at once, which can reduce response times in some architectures. Itâ€™s recommended to use the tools agent for OpenAI models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fff2766-defb-45fc-b271-3c811077076b",
      "metadata": {
        "gather": {
          "logged": 1713624045950
        }
      },
      "outputs": [],
      "source": [
        "agent = create_openai_tools_agent(llm.with_config(configurable={\"model\": \"gpt35\"}), tools, prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "338336d9-a64a-4602-908a-742b418e4520",
      "metadata": {},
      "source": [
        "Create an agent executor by passing in the agent and tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad6c156f-9a17-4daa-80de-70ce2f55063b",
      "metadata": {
        "gather": {
          "logged": 1713624046154
        }
      },
      "outputs": [],
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252a017c-3b36-43ab-8633-78f4f005d166",
      "metadata": {},
      "source": [
        "Give it memory - since AgentExecutor is also a Runnable class, we do the same with did on Notebook 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c013314-afe6-4218-b179-d0f7312d2670",
      "metadata": {
        "gather": {
          "logged": 1713624046357
        }
      },
      "outputs": [],
      "source": [
        "def get_session_history(session_id: str, user_id: str) -> CosmosDBChatMessageHistory:\n",
        "    cosmos = CosmosDBChatMessageHistory(\n",
        "        cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
        "        cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
        "        cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
        "        connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
        "        session_id=session_id,\n",
        "        user_id=user_id\n",
        "        )\n",
        "\n",
        "    # prepare the cosmosdb instance\n",
        "    cosmos.prepare_cosmos()\n",
        "    return cosmos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13df017f-3ab7-4943-adc1-3477badf3d3e",
      "metadata": {},
      "source": [
        "CosmosDBì—ëŠ” ë‘ ê°œì˜ í•„ë“œ(idì™€ íŒŒí‹°ì…˜)ê°€ í•„ìš”í•˜ê³ , RunnableWithMessageHistoryëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í•˜ë‚˜ì˜ ë©”ëª¨ë¦¬ ì‹ë³„ì(session_id)ë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ `history_factory_config` íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ê³  ë©”ëª¨ë¦¬ í´ë˜ìŠ¤ì— ëŒ€í•œ ì—¬ëŸ¬ í‚¤ë¥¼ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf93758f-da3b-48fb-9882-91fe327b1751",
      "metadata": {
        "gather": {
          "logged": 1713624046587
        }
      },
      "outputs": [],
      "source": [
        "userid_spec = ConfigurableFieldSpec(\n",
        "            id=\"user_id\",\n",
        "            annotation=str,\n",
        "            name=\"User ID\",\n",
        "            description=\"Unique identifier for the user.\",\n",
        "            default=\"\",\n",
        "            is_shared=True,\n",
        "        )\n",
        "session_id = ConfigurableFieldSpec(\n",
        "            id=\"session_id\",\n",
        "            annotation=str,\n",
        "            name=\"Session ID\",\n",
        "            description=\"Unique identifier for the conversation.\",\n",
        "            default=\"\",\n",
        "            is_shared=True,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d1aaa6-efca-4512-b680-896dae39a359",
      "metadata": {
        "gather": {
          "logged": 1713624046791
        }
      },
      "outputs": [],
      "source": [
        "agent_with_chat_history = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"question\",\n",
        "    history_messages_key=\"history\",\n",
        "    history_factory_config=[userid_spec,session_id]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c6b489-3db9-4965-9eae-ed2790e62bd7",
      "metadata": {
        "gather": {
          "logged": 1713624047055
        }
      },
      "outputs": [],
      "source": [
        "# configure the session id and user id\n",
        "random_session_id = \"session\"+ str(random.randint(1, 1000))\n",
        "ramdom_user_id = \"user\"+ str(random.randint(1, 1000))\n",
        "\n",
        "config={\"configurable\": {\"session_id\": random_session_id, \"user_id\": ramdom_user_id}}\n",
        "print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3295c54e-a5e2-46f6-99fc-6f76453a877d",
      "metadata": {},
      "source": [
        "Run the Agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac81763-6bcc-4408-9daf-d047a0e2cb08",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "agent_with_chat_history.invoke({\"question\": \"Hi, I'm Pablo Marin. What's yours\"}, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb3fca7e-33a1-40f1-afb0-dee441a1d1d5",
      "metadata": {
        "gather": {
          "logged": 1713624050152
        }
      },
      "outputs": [],
      "source": [
        "printmd(agent_with_chat_history.invoke(\n",
        "    {\"question\": \"Can I restore my index or service once it's deleted?\"}, \n",
        "    config=config)[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c430c456-f390-4319-a3b1-bee19da130cf",
      "metadata": {
        "gather": {
          "logged": 1713624056642
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    printmd(agent_with_chat_history.invoke(\n",
        "        {\"question\": \"Interesting, Can I move, backup, and restore indexes?\"},\n",
        "        config=config)[\"output\"])\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd54f71-03c9-4332-885b-0d1df942fa88",
      "metadata": {
        "gather": {
          "logged": 1713624058514
        }
      },
      "outputs": [],
      "source": [
        "printmd(agent_with_chat_history.invoke({\"question\": \"Thhank you!\"}, config=config)[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "149648ba-945d-4e7d-81f7-a8bca2ac87f2",
      "metadata": {},
      "source": [
        "#### Important: GPT3.5ì—ëŠ” ê¸´ í”„ë¡¬í”„íŠ¸ì™€ ê¸´ ë¬¸ë§¥, ìƒì„¸í•œ ë‹µë³€ì„ ì¶”ê°€í•˜ê¸° ì‹œì‘í•˜ê±°ë‚˜ ìƒë‹´ì›ì´ ì—¬ëŸ¬ ë‹¨ê³„ì˜ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ë²ˆ ê²€ìƒ‰í•˜ë©´ ê³µê°„ì´ ë¶€ì¡±í•˜ë‹¤ëŠ” í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤!\n",
        "\n",
        "ëª‡ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ì´ ë¬¸ì œë¥¼ í•´ì†Œí•  ìˆ˜ëŠ” ìˆìŠµë‹ˆë‹¤. \n",
        "- ë” ì§§ì€ System í”„ë¡¬í”„íŠ¸\n",
        "- ì²­í¬ë¥¼ ë” ì‘ê²Œ(ê¸°ë³¸ê°’ì¸ 5000ì ë¯¸ë§Œìœ¼ë¡œ)\n",
        "- ê´€ë ¨ì„±ì´ ë‚®ì€ ì²­í¬ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ topK ì¤„ì´ê¸°\n",
        "\n",
        "ê·¸ëŸ¬ë‚˜ ê¶ê·¹ì ìœ¼ë¡œ ëª¨ë“  ê²ƒì„ GPT3.5(ë” ì €ë ´í•˜ê³  ë¹ ë¥¸ ëª¨ë¸)ë¡œ ì‘ë™ì‹œí‚¤ê¸° ìœ„í•´ í’ˆì§ˆì„ í¬ê¸°í•´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41787714-73fd-4336-85f2-bec3abb41eda",
      "metadata": {},
      "source": [
        "### Let's add more things we have learned so far: dynamic LLM selection of GPT4 and asyncronous streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1511d2c3-97fe-4232-a560-014d0f157008",
      "metadata": {
        "gather": {
          "logged": 1713624058777
        }
      },
      "outputs": [],
      "source": [
        "agent = create_openai_tools_agent(llm.with_config(configurable={\"model\": \"gpt4\"}), tools, prompt) # We select now GPT-4\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
        "agent_with_chat_history = RunnableWithMessageHistory(agent_executor,get_session_history,input_messages_key=\"question\", \n",
        "                                                     history_messages_key=\"history\", history_factory_config=[userid_spec,session_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bec5b32-6017-44b9-97e7-34ba3695e688",
      "metadata": {},
      "source": [
        "ì´ì „ ë…¸íŠ¸ë¶ì—ì„œëŠ” í† í°ì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ê¸° ìœ„í•´ ì‹¤í–‰ ê°€ëŠ¥ í•¨ìˆ˜ì˜ `.stream()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.  However if you need to stream individual tokens from the agent or surface steps occuring within tools, you would need to use a combination of `Callbacks` and `.astream()` OR the new `astream_events` API (beta).\n",
        "\n",
        "ì—¬ê¸°ì„œëŠ” astream_events APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ì´ë²¤íŠ¸ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "    Agent Start with inputs\n",
        "    Tool Start with inputs\n",
        "    Tool End with outputs\n",
        "    Stream the agent final anwer token by token\n",
        "    Agent End with outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9600a35e-8d2e-43d0-a334-092b2e8b832c",
      "metadata": {
        "gather": {
          "logged": 1713624058976
        }
      },
      "outputs": [],
      "source": [
        "QUESTION = \"Tell me more about your last answer, search again multiple times and provide a deeper explanation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3808fa33-05bb-4f5d-9ab9-7159f6db62a8",
      "metadata": {
        "gather": {
          "logged": 1713624205700
        }
      },
      "outputs": [],
      "source": [
        "async for event in agent_with_chat_history.astream_events(\n",
        "    {\"question\": QUESTION}, config=config, version=\"v1\",\n",
        "):\n",
        "    kind = event[\"event\"]\n",
        "    if kind == \"on_chain_start\":\n",
        "        if (\n",
        "            event[\"name\"] == \"AgentExecutor\"\n",
        "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
        "            print(\n",
        "                f\"Starting agent: {event['name']}\"\n",
        "            )\n",
        "    elif kind == \"on_chain_end\":\n",
        "        if (\n",
        "            event[\"name\"] == \"AgentExecutor\"\n",
        "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
        "            print()\n",
        "            print(\"--\")\n",
        "            print(\n",
        "                f\"Done agent: {event['name']}\"\n",
        "            )\n",
        "    if kind == \"on_chat_model_stream\":\n",
        "        content = event[\"data\"][\"chunk\"].content\n",
        "        if content:\n",
        "            # Empty content in the context of OpenAI means\n",
        "            # that the model is asking for a tool to be invoked.\n",
        "            # So we only print non-empty content\n",
        "            print(content, end=\"\")\n",
        "    elif kind == \"on_tool_start\":\n",
        "        print(\"--\")\n",
        "        print(\n",
        "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
        "        )\n",
        "    elif kind == \"on_tool_end\":\n",
        "        print(f\"Done tool: {event['name']}\")\n",
        "        # print(f\"Tool output was: {event['data'].get('output')}\")\n",
        "        print(\"--\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b41bba7-18df-4ab8-b4f6-60368160d348",
      "metadata": {},
      "source": [
        "#### Note: ì´ ë§ˆì§€ë§‰ ì§ˆë¬¸ì„ GPT3.5ë¡œ ì‹¤í–‰í•˜ì—¬ LLMì˜ í† í° ê³µê°„ì´ ì–´ë–»ê²Œ ë¶€ì¡±í•´ì§€ëŠ”ì§€ í™•ì¸í•´ ë³´ì„¸ìš”."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0ec64bf-fe24-42fc-8dde-4d478f0af21e",
      "metadata": {},
      "source": [
        "# Summary\n",
        "\n",
        "We just built our first RAG BOT!.\n",
        "\n",
        "-  ë´‡ì„ êµ¬ì¶•í•˜ëŠ” ê°€ì¥ ì¢‹ì€ ë°©ë²•ì€ **ì—ì´ì „íŠ¸ + ë„êµ¬**ë¼ëŠ” ê²ƒì„ ì•Œê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. <br>\n",
        "- `utils.py`ì˜ `GetDocSearchResults_Tool` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ Azure Search ë¦¬íŠ¸ë¦¬ë²„(ê²€ìƒ‰ê¸°)ë¥¼ ë„êµ¬ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.\n",
        "- ìƒë‹´ì›ìœ¼ë¡œë¶€í„° ë‹µë³€ì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” í•œ ê°€ì§€ ë°©ë²•ì¸ ì´ë²¤íŠ¸ API(ë² íƒ€)ì— ëŒ€í•´ ì•Œê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "- í¬ê´„ì ì´ê³  ì–‘ì§ˆì˜ ë‹µë³€ì„ ì œê³µí•˜ê¸° ìœ„í•´ì„œëŠ” GPT3.5ë¡œëŠ” ê³µê°„ì´ ë¶€ì¡±í•˜ë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ê²°êµ­ GPT4ê°€ í•„ìš”í•˜ê²Œ ë©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56306506-d53d-4d43-93e2-a9300ed2a3ee",
      "metadata": {},
      "source": [
        "# NEXT\n",
        "ì´ì œ í•˜ë‚˜ì˜ ìŠ¤í‚¬(ë¬¸ì„œ ê²€ìƒ‰)ì„ ê°€ì§„ ë´‡ì´ ìƒê²¼ìœ¼ë‹ˆ ë” ë§ì€ ìŠ¤í‚¬ì„ ë§Œë“¤ì–´ ë´…ì‹œë‹¤! \n",
        "\n",
        "ë‹¤ìŒ ë…¸íŠ¸ë¶ì—ì„œëŠ” ëª¨ë“  ê¸°ëŠ¥ì„ í•˜ë‚˜ë¡œ ë¬¶ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. \n",
        "\n",
        "ëª¨ë“  ë…¸íŠ¸ë¶ì˜ ê¸°ëŠ¥ì„ ì–´ë–»ê²Œ í™œìš©í•˜ê³  ê·¸ì— ë”°ë¼ ì–´ë–¤ ìš”ì²­ì—ë„ ì‘ë‹µí•  ìˆ˜ ìˆëŠ” ë‘ë‡Œ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì„ê¹Œìš”?"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

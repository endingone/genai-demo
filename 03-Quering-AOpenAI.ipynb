{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d59d527f-1100-45ff-b051-5f7c9029d94d",
      "metadata": {},
      "source": [
        "# Queries with and without Azure OpenAI"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "eb9a9444-dc90-4fc3-aea7-8ee918301aba",
      "metadata": {},
      "source": [
        "지금까지 인덱스의 데이터 소스에서 검색 엔진을 로드했습니다. 이 노트북에서는 몇 가지 예제 쿼리를 시도한 다음 Azure OpenAI 서비스를 사용하여 사용자 쿼리에 대한 올바른 답변을 얻을 수 있는지 살펴보겠습니다.\n",
        "\n",
        "사용자가 콘토소 일렉트로닉스 HR 문서에 대해 질문하면 엔진이 그에 따라 응답하는 것입니다. 이 단일 인덱스 데모는 회사에서 완전히 다른 주제에 대해 서로 다른 유형의 단일 문서를 로드하고 검색 엔진이 가장 관련성이 높은 결과로 응답해야 하는 시나리오를 모방한 것입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08",
      "metadata": {},
      "source": [
        "## Set up variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f",
      "metadata": {
        "gather": {
          "logged": 1713623499018
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib\n",
        "import requests\n",
        "import random\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "from IPython.display import display, HTML, Markdown\n",
        "from typing import List\n",
        "from operator import itemgetter\n",
        "\n",
        "# LangChain Imports needed\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "\n",
        "\n",
        "# Our own libraries needed\n",
        "from common.prompts import DOCSEARCH_PROMPT\n",
        "from common.utils import get_search_results\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f2c22f8-79ab-405c-95e8-77a1978e53bc",
      "metadata": {
        "gather": {
          "logged": 1713623499496
        }
      },
      "outputs": [],
      "source": [
        "# Setup the Payloads header\n",
        "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
        "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9297d29b-1f61-4dce-858e-bf4272172dba",
      "metadata": {},
      "source": [
        "## Single-Index Search queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a46e2d3-298a-4708-83de-9e108b1a117a",
      "metadata": {
        "gather": {
          "logged": 1713623499809
        },
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Text-based Indexe that we are going to query (from Notebook 01)\n",
        "index_name = \"cogsrch-index-hrdocs\"\n",
        "indexes = [index_name]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1c62ebb2-d7be-4bfb-b1ba-4db86c11839a",
      "metadata": {},
      "source": [
        "건강 보험, 직원에 대한 직무 설명과 같이 Contoso Electronic의 정책에서 답변하거나 다룰 수 있다고 생각되는 질문을 해보세요. 결과를 ChatGPT의 오픈 버전과 비교해 보세요. <br>\n",
        "\n",
        "Azure OpenAI를 사용한 답변은 이러한 게시물에 포함된 정보만 살펴본다는 점을 기억하세요.\n",
        "\n",
        "**Example Questions you can ask**:\n",
        "- What is our mission?\n",
        "- How do we review the performance?\n",
        "- What is the responsibility of Manager of Human Resources?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead",
      "metadata": {
        "gather": {
          "logged": 1713623500111
        }
      },
      "outputs": [],
      "source": [
        "QUESTION = \"What is the responsibility of Manager of Human Resources?\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6d925eb-7f9c-429e-a62a-4c37d7702caf",
      "metadata": {},
      "source": [
        "### Search on an index\n",
        "\n",
        "#### **Note**:\n",
        "멀티 인덱스도 사용할 수 있습니다. 멀티 인덱스를 사용하려면 다음과 같이 하세요. \n",
        "\n",
        "표준화 인덱스를 사용해야 합니다. 인덱스를 표준화하려면 **각 인덱스에 6개의 필수 필드가 있어야 합니다**:\n",
        "6개 필수 필드는 `id, title, name, location, chunk, chunkVector`입니다.\n",
        "\n",
        "이는 각 문서가 코드 상에서 동일하게 취급될 수 있도록 하기 위함입니다. 또한 **모든 인덱스에는 시맨틱 구성이 있어야 합니다**.\n",
        "\n",
        "하이브리드 쿼리를 사용하겠습니다. 최적의 결과를 위해 텍스트 + 벡터 검색을 결합한 하이브리드 쿼리를 사용하겠습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faf2e30f-e71f-4533-ab52-27d048b80a89",
      "metadata": {
        "gather": {
          "logged": 1713623500424
        }
      },
      "outputs": [],
      "source": [
        "agg_search_results = dict()\n",
        "k = 10\n",
        "\n",
        "for index in indexes:\n",
        "    search_payload = {\n",
        "        \"search\": QUESTION, # Text query\n",
        "        \"select\": \"id, title, name, location, chunk\",\n",
        "        \"queryType\": \"semantic\",\n",
        "        \"vectorQueries\": [{\"text\": QUESTION, \"fields\": \"chunkVector\", \"kind\": \"text\", \"k\": k}], # Vector query\n",
        "        \"semanticConfiguration\": \"my-semantic-config\",\n",
        "        \"captions\": \"extractive\",\n",
        "        \"answers\": \"extractive\",\n",
        "        \"count\":\"true\",\n",
        "        \"top\": k\n",
        "    }\n",
        "\n",
        "    r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + index + \"/docs/search\",\n",
        "                     data=json.dumps(search_payload), headers=headers, params=params)\n",
        "    print(r.status_code)\n",
        "\n",
        "    search_results = r.json()\n",
        "    agg_search_results[index]=search_results\n",
        "    print(\"Index:\", index, \"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7fd0fe5-4ee0-42e2-a920-72b93a407389",
      "metadata": {
        "tags": []
      },
      "source": [
        "### 점수에 따라 상위 검색 결과(검색 결과)를 표시하기 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e938337-602d-4b61-8141-b8c92a5d91da",
      "metadata": {
        "gather": {
          "logged": 1713623501718
        }
      },
      "outputs": [],
      "source": [
        "display(HTML('<h4>Top Answers</h4>'))\n",
        "\n",
        "for index,search_results in agg_search_results.items():\n",
        "    for result in search_results['@search.answers']:\n",
        "        if result['score'] > 0.5: # Show answers that are at least 50% of the max possible score=1\n",
        "            display(HTML('<h5>' + 'Answer - score: ' + str(round(result['score'],2)) + '</h5>'))\n",
        "            display(HTML(result['text']))\n",
        "            \n",
        "print(\"\\n\\n\")\n",
        "display(HTML('<h4>Top Results</h4>'))\n",
        "\n",
        "content = dict()\n",
        "ordered_content = OrderedDict()\n",
        "\n",
        "\n",
        "for index,search_results in agg_search_results.items():\n",
        "    for result in search_results['value']:\n",
        "        if result['@search.rerankerScore'] > 1:# Show answers that are at least 25% of the max possible score=4\n",
        "            content[result['id']]={\n",
        "                                    \"title\": result['title'],\n",
        "                                    \"chunk\": result['chunk'], \n",
        "                                    \"name\": result['name'], \n",
        "                                    \"location\": result['location'] ,\n",
        "                                    \"caption\": result['@search.captions'][0]['text'],\n",
        "                                    \"score\": result['@search.rerankerScore'],\n",
        "                                    \"index\": index\n",
        "                                    }\n",
        "    \n",
        "#After results have been filtered we will Sort and add them as an Ordered list\\n\",\n",
        "for id in sorted(content, key= lambda x: content[x][\"score\"], reverse=True):\n",
        "    ordered_content[id] = content[id]\n",
        "    url = str(ordered_content[id]['location']) + os.environ['BLOB_SAS_TOKEN']\n",
        "    title = str(ordered_content[id]['title']) if (ordered_content[id]['title']) else ordered_content[id]['name']\n",
        "    score = str(round(ordered_content[id]['score'],2))\n",
        "    display(HTML('<h5><a href=\"'+ url + '\">' + title + '</a> - score: '+ score + '</h5>'))\n",
        "    display(HTML(ordered_content[id]['caption']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52a6d3e6-afb2-4fa7-96d3-69bc2373ded5",
      "metadata": {},
      "source": [
        "### 쿼리 결과에 대한 코멘트"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e02227-6a92-4944-86f8-6c1e38d90fe4",
      "metadata": {},
      "source": [
        "위에서 본 바와 같이 Azure AI 검색 서비스의 시맨틱 리랭크 기능은 훌륭합니다. \n",
        "때로는 답변과 함께 해당 파일과 답변이 가능한 단락이 있는 상위 결과도 제공합니다.\n",
        "\n",
        "Azure OpenAI로 이 기능을 더 개선할 수 있는지 살펴봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8df3e6d4-9a09-4b0f-b328-238738ccfaec",
      "metadata": {},
      "source": [
        "# Using Azure OpenAI\n",
        "\n",
        "OpenAI를 사용하여 질문에 대한 더 나은 답변을 얻기 위한 일련의 사고 과정은 간단합니다.  검색 결과의 답변과 문서 내용을 컨텍스트로 GPT 모델에 제공**하고 더 나은 답변을 제공하도록 하는 것입니다. 이것이 바로 RAG(Retreival Augmented Generation, 검색 증강 생성)입니다.\n",
        "\n",
        "이제 이 작업을 수행하기 전에 몇 가지 사항을 먼저 이해해야 합니다.\n",
        "\n",
        "1) Chainning and Prompt Engineering \n",
        "2) Embeddings\n",
        "\n",
        "우리는 많은 상용구 코드를 패키징하는 **LangChain**이라는 라이브러리를 사용할 것입니다.\n",
        "Langchain은 내부에서 많은 프롬프트 엔지니어링을 수행하는 라이브러리 중 하나이며, 자세한 내용은 [여기](https://python.langchain.com/en/latest/index.html)를 참조하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665",
      "metadata": {
        "gather": {
          "logged": 1713623502038
        }
      },
      "outputs": [],
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "325d9138-2250-4f6b-bc88-50d7957f8d33",
      "metadata": {},
      "source": [
        "**Important Note**: 지금부터 OpenAI 모델을 활용합니다. Azure OpenAI 포털 내에서 다음 모델을 배포했는지 확인하세요. \n",
        "\n",
        "- text-embedding-ada-002 (or newer)\n",
        "- gpt-35-turbo (1106 or newer)\n",
        "- gpt-4-turbo (1106 or newer)\n",
        "\n",
        "Reference for Azure OpenAI models (regions, limits, dimensions, etc): [HERE](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e7c720e-ece1-45ad-9d01-2dfd15c182bb",
      "metadata": {},
      "source": [
        "## chaining LLMs과 prompt engineering에 대한 소개"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2bcd7028-5a6c-4296-8c85-4f420d408d69",
      "metadata": {},
      "source": [
        "체인은 LLM, 도구 또는 데이터 전처리 단계에 대한 호출 시퀀스를 나타냅니다.\n",
        "\n",
        "Azure OpenAI는 사용할 수 있는 LLM(공급자)의 한 유형이지만 Cohere, Huggingface 등과 같은 다른 유형도 있습니다.\n",
        "\n",
        "체인은 단순(예: 일반) 또는 전문화(예: 유틸리티)될 수 있습니다.\n",
        "\n",
        "일반 - 가장 간단한 체인은 단일 LLM입니다. 입력 프롬프트와 LLM의 이름을 받은 다음 텍스트 생성(즉, 프롬프트에 대한 출력)에 LLM을 사용합니다. 다음은 예시입니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13df9247-e784-4e04-9475-55e672efea47",
      "metadata": {
        "gather": {
          "logged": 1713623502341
        }
      },
      "outputs": [],
      "source": [
        "COMPLETION_TOKENS = 2500\n",
        "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], \n",
        "                      temperature=0, \n",
        "                      max_tokens=COMPLETION_TOKENS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b55adb-6f98-4f15-b67a-9fbba5820560",
      "metadata": {
        "gather": {
          "logged": 1713623502577
        }
      },
      "outputs": [],
      "source": [
        "output_parser = StrOutputParser()\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an assistant that give thorough responses to users.\"),\n",
        "    (\"user\", \"{input}. Give your response in {language}\")\n",
        "])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6417d052-0035-4635-93e8-2bd3ec50d796",
      "metadata": {},
      "source": [
        " | 기호는 유닉스 파이프 연산자와 유사하며, 서로 다른 컴포넌트를 연결하여 한 컴포넌트의 출력을 다음 컴포넌트의 입력으로 공급하는 역할을 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a37e60-a1ef-4750-a1ec-9e4fe5ba07fa",
      "metadata": {
        "gather": {
          "logged": 1713623502812
        }
      },
      "outputs": [],
      "source": [
        "chain = prompt | llm | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6be6b4df-ee2c-4a0c-8ad3-a672d70f4f8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "display(Markdown(chain.invoke({\"input\": QUESTION, \"language\": \"English\"})))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cd8539d0-a538-4368-82c3-5f91d8370f1e",
      "metadata": {},
      "source": [
        "**참고**: 이 액셀러레이터에서 OpenAI를 처음 사용하는 경우, 리소스를 찾을 수 없음 오류가 발생하면 OpenAI 모델 배포 이름이 위에 설정된 환경 변수 os.environ[\"GPT35_DEPLOYMENT_NAME\"]과 다르기 때문일 가능성이 높습니다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "50ed014c-0c6b-448c-b995-fe7970b92ad5",
      "metadata": {},
      "source": [
        "이제 간단한 프롬프트를 생성하고 ChatGPT 지식을 사용하여 일반적인 질문에 답하기 위해 체인을 사용하는 방법을 알게 되었습니다!\n",
        "\n",
        "일반 체인을 독립형 체인으로 사용하는 경우는 거의 없다는 점에 유의하는 것이 중요합니다. 더 자주 유틸리티 체인의 빌딩 블록으로 사용됩니다 (다음에 살펴보겠습니다). 또한 주목해야 할 중요한 점은 아직 문서나 Azure 검색 결과를 사용하는 것이 아니라 학습된 데이터에 대한 ChatGPT의 지식만 사용한다는 것입니다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "12c48038-b1af-4228-8ffb-720e554fd3b2",
      "metadata": {
        "tags": []
      },
      "source": [
        "**두 번째 유형의 체인은 유틸리티입니다.**\n",
        "\n",
        "유틸리티 - 특정 작업을 해결하는 데 도움이 되는 여러 빌딩 블록으로 구성된 전문화된 체인입니다. \n",
        "<br> 예를 들어, LangChain은 일부 엔드투엔드 체인을 지원합니다(예: QnA 문서 검색, 요약 등을 위한 create_retrieval_chain).\n",
        "\n",
        "이 워크샵에서는 더 깊이 파고들기 위해 자체적으로 특정 체인을 구축하고 Azure AI Search의 결과를 개선하는 사용 사례를 해결해 보겠습니다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b0454ddb-44d8-4fa9-929a-5e5563dd28f8",
      "metadata": {},
      "source": [
        "하지만 필요한 유틸리티 체인을 다루기 전에 먼저 임베딩과 벡터 검색 및 RAG의 개념을 살펴봅시다.\n",
        "\n",
        "## Embeddings and Vector Search\n",
        "\n",
        "Azure OpenAI 에서 임베딩은 기계 학습 모델 및 알고리즘에서 쉽게 활용할 수 있는 특별한 형식의 데이터 표현입니다. 임베딩은 텍스트의 의미론적 의미를 밀도 있게 표현한 정보입니다. 각 임베딩은 부동 소수점 숫자로 이루어진 벡터로, 벡터 공간에서 두 임베딩 사이의 거리는 원래 형식의 두 입력 사이의 의미적 유사성과 상관관계가 있습니다. 예를 들어 두 텍스트가 유사하다면 벡터 표현도 유사해야 합니다.\n",
        "\n",
        "\n",
        "\n",
        "### Why Do We Need Vectors?\n",
        "\n",
        "벡터는 여러 가지 이유로 필수적입니다:\n",
        "\n",
        "- **의미론적 풍부함**: 벡터는 텍스트의 의미론적 의미를 수학적 벡터로 변환하여 단순한 키워드 검색으로는 놓칠 수 있는 뉘앙스를 포착합니다. 따라서 언어를 이해하고 처리하는 데 매우 강력합니다.\n",
        "- **인간과 유사한 검색**: 벡터 거리를 이용한 검색은 정확한 단어 일치에만 의존하지 않고 문맥과 의미에 따라 정보를 찾는 인간의 접근 방식을 모방합니다.\n",
        "- **규모의 효율성**: 벡터 표현을 사용하면 대규모 데이터 세트를 효율적으로 처리하고 검색할 수 있습니다. 복잡한 텍스트를 숫자 벡터로 줄임으로써 알고리즘은 방대한 양의 정보를 빠르게 선별할 수 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "### Understanding LLM Tokens' Context Limitation\n",
        "\n",
        "GPT와 같은 대규모 언어 모델(LLM)에는 각 입력에 대한 토큰 제한이 있어 긴 문서나 광범위한 데이터 세트를 다룰 때 문제가 됩니다. 이러한 제한은 제공된 정보의 전체 맥락에 따라 이해하고 응답을 생성하는 모델의 능력을 제한합니다. 따라서 이러한 제한을 효과적으로 관리하고 우회하여 LLM의 성능을 최대한 활용할 수 있는 전략을 수립하는 것이 매우 중요합니다.\n",
        "\n",
        "이 문제를 해결하기 위해 이 솔루션에는 몇 가지 주요 단계가 포함되어 있습니다.\n",
        "\n",
        "1. 문서 세분화: 대용량 문서를 관리하기 쉬운 작은 세그먼트로 세분화합니다. \n",
        "2. 청크의 벡터화: 이러한 세그먼트를 벡터로 변환해 벡터 기반 검색 기술과 호환되도록 합니다. \n",
        "3. 하이브리드 검색: 벡터 및 텍스트 검색 방법을 모두 사용하여 쿼리와 관련하여 가장 관련성이 높은 세그먼트를 찾아냅니다. \n",
        "4. 최적의 컨텍스트 제공: 가장 관련성이 높은 세그먼트를 LLM에 제시하여 토큰 한도 내에서 세부 사항과 간결함 사이의 균형을 유지합니다.\n",
        "\n",
        "우리의 궁극적인 목표는 벡터 인덱스와 하이브리드 검색(벡터 + 텍스트)에만 의존하는 것입니다. 다양한 파일 형식에 대해 OCR을 사용하여 파서를 수동으로 코딩하고 데이터를 인덱스와 동기화하는 스케줄러를 개발할 수도 있지만, 더 효율적인 대안이 있습니다: 바로 자동화된 청킹 전략과 벡터화를 제공하는 Azure AI Search입니다. 'ordered_content' 사전에서 볼 수 있듯이 문서 세분화 및 벡터화는 이미 AI Azure Search에서 완료되었다는 점에 유의해야 합니다. 이 전처리 단계는 후속 작업을 간소화하여 빠른 응답 시간을 보장하고 선택한 OpenAI 모델의 토큰 한도를 준수합니다.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "80e79235-3d8b-4713-9336-5004cc4a1556",
      "metadata": {},
      "source": [
        "따라서 이제 우리가 할 일은 Azure AI 검색 쿼리의 결과가 LLM 컨텍스트 크기에 맞는지 확인한 다음 마법이 작동하도록 내버려두는 것뿐입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12682a1b-df92-49ce-a638-7277103f6cb3",
      "metadata": {
        "gather": {
          "logged": 1713623508323
        }
      },
      "outputs": [],
      "source": [
        "index_name = \"cogsrch-index-hrdocs\"\n",
        "indexes = [index_name]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "78a6d6a7-18ef-45b2-a216-3c1f50006593",
      "metadata": {},
      "source": [
        "코드 중복을 피하기 위해 위에서 사용한 많은 코드를 함수에 넣었습니다. 이러한 함수는 common/utils.py 및 common/prompts.py 파일에 있습니다. 이렇게 하면 나중에 빌드할 앱에서 이러한 함수를 사용할 수 있습니다.\n",
        "\n",
        "get_search_results()는 다중 인덱스 검색을 수행하고 문서/청크의 결합된 정렬된 목록을 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bccca45-d1dd-476f-b109-a528b857b6b3",
      "metadata": {
        "gather": {
          "logged": 1713623509989
        }
      },
      "outputs": [],
      "source": [
        "k = 10  # play with this parameter and see the quality of the final answer\n",
        "ordered_results = get_search_results(QUESTION, indexes, k=k, reranker_threshold=1)\n",
        "print(\"Number of results:\",len(ordered_results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9334b4b-a378-4d99-b04b-4762d35e8c0a",
      "metadata": {
        "gather": {
          "logged": 1713623510357
        }
      },
      "outputs": [],
      "source": [
        "top_docs = []\n",
        "for key,value in ordered_results.items():\n",
        "    if value[\"score\"] > 3:\n",
        "        location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
        "        top_docs.append(Document(page_content=value[\"chunk\"], metadata={\"source\": location, \"score\":value[\"score\"]}))\n",
        "\n",
        "print(\"Number of filtered results:\",len(top_docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffed0ea2-1d21-477b-a6cd-20621589e204",
      "metadata": {
        "gather": {
          "logged": 1713623515691
        }
      },
      "outputs": [],
      "source": [
        "chain = (\n",
        "    DOCSEARCH_PROMPT  # Passes the 4 variables above to the prompt template\n",
        "    | llm   # Passes the finished prompt to the LLM\n",
        "    | StrOutputParser()  # converts the output (Runnable object) to the desired output (string)\n",
        ")\n",
        "\n",
        "answer = chain.invoke({\"question\": QUESTION, \"context\":top_docs})\n",
        "\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "406c2b91-6752-4ea2-b95c-d1a52dbdd62b",
      "metadata": {},
      "source": [
        "### From GPT-3.5 to GPT-4\n",
        "\n",
        "이제 GPT-4로 변경하면 응답이 어떻게 바뀌는지 살펴보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f01705f1-7194-452b-a170-c09ba7752b1d",
      "metadata": {
        "gather": {
          "logged": 1713623519188
        }
      },
      "outputs": [],
      "source": [
        "llm_2 = AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS)\n",
        "chain = DOCSEARCH_PROMPT | llm_2 | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c83bb17-36d3-4eb6-ae6f-9c68f3033d2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "try:\n",
        "    display(Markdown(chain.invoke({\"question\": QUESTION, \"context\": top_docs})))\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92a28869-13c1-463e-8285-9870e6ac1946",
      "metadata": {},
      "source": [
        "#### As we can see, the model selection MATTERS!\n",
        "\n",
        "이에 대해서는 나중에 자세히 살펴보겠지만, 지금은 **품질과 응답 시간에서 GPT3.5와 GPT4의 차이점을 살펴보겠습니다**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "417925af-486a-40bc-a290-28c35968c581",
      "metadata": {},
      "source": [
        "# 프롬프트 개선 및 인용구 추가\n",
        "\n",
        "위에서 \"사용자에 대한 철저한 대응\"이라는 메시지가 표시되어 있음에도 불구하고 GPT3.5의 답변은 GPT4에 비해 매우 단순하다는 것을 알 수 있습니다. 또한 인용이나 참고 문헌이 없다는 것도 확인할 수 있었습니다. **답변이 문맥에 근거한 것인지 아닌지 어떻게 알 수 있을까요?**\n",
        "\n",
        "프롬프트 엔지니어링으로 이 두 가지 문제를 개선할 수 있는지 살펴봅시다.\n",
        "`common/prompts.py`에 `DOCSEARCH_PROMPT`라는 프롬프트를 만들었으니 확인해 보세요!\n",
        "\n",
        "\n",
        "또한 체인 building 내에서 쉽게 연결할 수 있도록 사용자 정의 리트리버 클래스를 만들어 보겠습니다. \n",
        "참고: Azure AI 검색 리트리버 클래스 [여기](https://python.langchain.com/docs/integrations/vectorstores/azuresearch)를 사용할 수도 있지만, 다음과 같은 이유로 사용자 지정 리트리버를 만들고자 합니다.\n",
        "\n",
        "\n",
        "1) 한 번의 호출로 멀티 인덱스 검색 즉 여러 인덱스를 검색을 수행하려고 합니다.\n",
        "2) 이 노트북에서 LangChain의 복잡한 개념을 더 쉽게 가르칠 수 있습니다.\n",
        "3) REST API를 사용하려는 경우와 Python Azure Search SDK를 사용하려는 경우의 차이를 이해합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdf31f99-0dfb-423a-81f5-03018e61d9a9",
      "metadata": {
        "gather": {
          "logged": 1713623539608
        }
      },
      "outputs": [],
      "source": [
        "class CustomRetriever(BaseRetriever):\n",
        "    \n",
        "    topK : int\n",
        "    reranker_threshold : int\n",
        "    indexes: List\n",
        "    sas_token: str = None\n",
        "    \n",
        "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        \n",
        "        ordered_results = get_search_results(query, self.indexes, k=self.topK, \n",
        "                                             reranker_threshold=self.reranker_threshold, \n",
        "                                             sas_token=self.sas_token)\n",
        "        top_docs = []\n",
        "        for key,value in ordered_results.items():\n",
        "            location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
        "            top_docs.append(Document(page_content=value[\"chunk\"], metadata={\"source\": location, \"score\":value[\"score\"]}))\n",
        "\n",
        "        return top_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19b39c79-c827-4437-b58b-6a6fae53b968",
      "metadata": {
        "gather": {
          "logged": 1713623539968
        }
      },
      "outputs": [],
      "source": [
        "# Create the retriever\n",
        "retriever = CustomRetriever(indexes=indexes, topK=k, reranker_threshold=1, sas_token=os.environ['BLOB_SAS_TOKEN'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7aa4f58-4791-40a0-80c5-6582e0574579",
      "metadata": {
        "gather": {
          "logged": 1713623540656
        }
      },
      "outputs": [],
      "source": [
        "# Test retreiver\n",
        "results = retriever.get_relevant_documents(QUESTION)\n",
        "len(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b6546f-b5c5-4168-97fc-2636c50e41c2",
      "metadata": {
        "gather": {
          "logged": 1713623540957
        }
      },
      "outputs": [],
      "source": [
        "# We can create now a dynamically configurable llm object that can change the model at runtime\n",
        "dynamic_llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], \n",
        "                              temperature=0.5, max_tokens=COMPLETION_TOKENS).configurable_alternatives(\n",
        "    # This gives this field an id\n",
        "    # When configuring the end runnable, we can then use this id to configure this field\n",
        "    ConfigurableField(id=\"model\"),\n",
        "    # This sets a default_key.\n",
        "    # If we specify this key, the default LLM  (initialized above) will be used\n",
        "    default_key=\"gpt35\",\n",
        "    # This adds a new option, with name `gpt4`\n",
        "    gpt4=AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], \n",
        "                         temperature=0.5, max_tokens=COMPLETION_TOKENS),\n",
        "    # You can add more configuration options here\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7da2f31-cf5d-4f3a-aad5-67b50b56968e",
      "metadata": {
        "gather": {
          "logged": 1713623541288
        }
      },
      "outputs": [],
      "source": [
        "# Declaration of the chain with the dynamic llm and the new prompt\n",
        "configurable_chain = (\n",
        "    {\n",
        "        \"context\": itemgetter(\"question\") | retriever, # Passes the question to the retriever and the results are assign to context\n",
        "        \"question\": itemgetter(\"question\")\n",
        "    }\n",
        "    | DOCSEARCH_PROMPT  # Passes the input variables above to the prompt template\n",
        "    | dynamic_llm   # Passes the finished prompt to the LLM\n",
        "    | StrOutputParser()  # converts the output (Runnable object) to the desired output (string)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b67200e5-d3ae-4c86-9f69-bc7b964ab532",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "try:\n",
        "    display(Markdown(configurable_chain.with_config(configurable={\"model\": \"gpt35\"}).invoke({\"question\": QUESTION})))\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8661b48d-1e57-4a70-9b0a-cc59f9093267",
      "metadata": {},
      "source": [
        "위에서 보았듯이 프롬프트 엔지니어링만으로 답변의 품질과 완성도를 높이고 인용을 추가할 수 있었습니다!\n",
        "\n",
        "\n",
        "다시 GPT-4를 시도해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efcfac6b-bac2-40c6-9ded-e4ee38e3093f",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "try:\n",
        "    display(Markdown(configurable_chain.with_config(configurable={\"model\": \"gpt4\"}).invoke({\"question\": QUESTION})))\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c93b000a-8d0a-4574-be7c-48d26dfb4c70",
      "metadata": {},
      "source": [
        "#### 보다시피 GPT4의 답변은 더 풍부하고 모든 관련 청크를 포함합니다. GPT3.5는 첫 번째와 마지막 청크에만 집중하는 경향이 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6690453b-a9b1-4907-bd43-8c6b3ecba26e",
      "metadata": {},
      "source": [
        "## Adding Streaming to improve user experience and performance\n",
        "\n",
        "이쯤 되면 **GPT4 답변이 GPT3.5**보다 품질이 더 우수하다는 것을 알 수 있습니다. 틀린 답은 없지만, 문맥을 이해하고 프롬프트 지침을 따르며 포괄적인 답변을 제공하는 데 있어서는 GPT4가 더 우수합니다.\n",
        "\n",
        "GPT4를 더 빠르게 보이게 하는 한 가지 방법은 사용자가 입력하는 대로 답변을 볼 수 있도록 답변을 스트리밍하는 것입니다. 이렇게 하려면 `invoke` 대신 `stream` 메서드를 호출하기만 하면 됩니다. 나중에 노트북에서 스트리밍과 콜백에 대해 자세히 설명하지만, 지금은 간단한 방법을 소개합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d250c88-5984-438f-8390-1d93756048ab",
      "metadata": {
        "gather": {
          "logged": 1713623658630
        }
      },
      "outputs": [],
      "source": [
        "for chunk in configurable_chain.with_config(configurable={\"model\": \"gpt4\"}).stream({\"question\": QUESTION}):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f347373a-a5be-473d-b64e-0f6b6dbcd0e0",
      "metadata": {},
      "source": [
        "# Summary\n",
        "##### OpenAI를 사용하면 사용자 질문에 대한 답변이 Azure AI Search의 결과만 가져오는 것보다 훨씬 더 나은 결과를 얻을 수 있습니다. 요약하면 다음과 같습니다. \n",
        "- Azure AI Search를 활용하여 문서의 상위 chunk를 식별하는 단일 인덱스 하이브리드 검색을 수행합니다.\n",
        "- 그런 다음, Azure OpenAI는 이러한 추출된 청크를 컨텍스트로 활용하고 콘텐츠를 이해한 후 최적의 답변을 제공하는 데 사용합니다.\n",
        "- Best of two worlds!\n",
        "\n",
        "##### Important observations on this notebook:\n",
        "\n",
        "1) GPT-3.5를 사용한 답변은 품질은 떨어지지만 훨씬 빠릅니다.\n",
        "2) GPT-3.5를 사용한 답변이 올바른 형식의 인용을 찾지 못하는 경우가 있습니다.\n",
        "3) GPT-4를 사용한 답변은 품질은 우수하지만 속도가 훨씬 느립니다.\n",
        "4) GPT-4를 사용한 답변은 항상 올바른 형식의 우수하고 다양한 인용을 제공합니다.\n",
        "5) 답변을 스트리밍하면 사용자 경험이 크게 향상됩니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc6e2fe-1c34-4952-99ad-14940f022379",
      "metadata": {},
      "source": [
        "# NEXT\n",
        "다음 노트북에서는 벡터 검색을 사용하여 복잡하고 큰 문서를 개별적으로 처리하는 방법을 살펴보겠습니다."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

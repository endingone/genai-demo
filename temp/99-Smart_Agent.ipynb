{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6423f8f3-a592-4ee7-9969-39e38933be52",
      "metadata": {},
      "source": [
        "# Putting it all together"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06bf854d-94d7-4a65-952a-22c7999a9a9b",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "So far we have done the following on the prior Notebooks:\n",
        "\n",
        "- **Notebook 01**: \"cogsrch-index-files\" 인덱스에 강화된 PDF가 포함된 Azure 검색 엔진을 로드했습니다.\n",
        "- **Notebook 02**: LLM의 유틸리티 체인을 사용하여 답변 생성을 향상시키기 위해 AzureOpenAI GPT 모델을 추가했습니다.\n",
        "- **Notebook 03**: 대용량/복잡한 PDF 정보가 포함된 인덱스(\"cogsrch-index-books\")를 수동으로 로드했습니다.\n",
        "- **Notebook 04**: 대화형 Chat Bot을 강화하기 위해 시스템에 메모리를 추가했습니다.\n",
        "- **Notebook 05**: 에이전트와 Tool(도구)를 도입하고 검색 엔진을 통해 RAG를 수행할 수 있는 최초의 Skill/Agent를 구축했습니다.\n",
        "\n",
        "한 가지 더 놓친 것이 있습니다: **이 모든 기능을 어떻게 하면 매우 스마트한 GPT 스마트 검색 엔진 채팅 봇으로 통합할 수 있을까요?**\n",
        "\n",
        "우리는 질문을 받고, 어떤 Tool을 사용할지 생각하고, 답을 얻을 수 있는 가상 비서를 원합니다. 목표는 정보의 출처(검색 엔진, Bing 검색, SQL 데이터베이스, CSV 파일, JSON 파일, API 등)에 관계없이 어시스턴트가 올바른 Tool을 사용하여 질문에 올바르게 답변할 수 있도록 하는 것입니다.<br>.\n",
        "\n",
        "에이전트는 사용할 수 있는 더 많은 Tool을 구축할 수 있습니다.\n",
        "\n",
        "이 노트북에서는 '두뇌' 에이전트(마스터 에이전트라고도 함)를 만들 것입니다.\n",
        "\n",
        "1) 질문을 이해하고 사용자와 상호 작용합니다. \n",
        "2) 다른 소스에 연결된 다른 전문 에이전트와 대화합니다.\n",
        "3) 답변을 얻으면 사용자에게 전달하거나 전문 에이전트가 직접 전달하도록 합니다.\n",
        "\n",
        "This is the same concept of [AutoGen](https://www.microsoft.com/en-us/research/blog/autogen-enabling-next-generation-large-language-model-applications/): Agents talking to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d7fa9dc-64cb-4ee2-ae98-8cdb72293cbe",
      "metadata": {},
      "source": [
        "![image](./images/AutoGen_Fig1.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b81551-92ac-4f08-9c00-ba11981c67c2",
      "metadata": {
        "gather": {
          "logged": 1713624248704
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import json\n",
        "import requests\n",
        "from operator import itemgetter\n",
        "from typing import Union, List\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.agents import AgentExecutor, Tool, create_openai_tools_agent\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory, CosmosDBChatMessageHistory\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.runnables import ConfigurableFieldSpec, ConfigurableField\n",
        "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.output_parsers import JsonOutputToolsParser\n",
        "from langchain_core.runnables import (\n",
        "    Runnable,\n",
        "    RunnableLambda,\n",
        "    RunnableMap,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "\n",
        "#custom libraries that we will use later in the app\n",
        "from common.utils import (\n",
        "    DocSearchAgent, \n",
        "    CSVTabularAgent, \n",
        "    SQLSearchAgent, \n",
        "    ChatGPTTool, \n",
        "    BingSearchAgent, \n",
        "    APISearchAgent, \n",
        "    reduce_openapi_spec\n",
        ")\n",
        "from common.callbacks import StdOutCallbackHandler\n",
        "from common.prompts import CUSTOM_CHATBOT_PROMPT \n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "from IPython.display import Markdown, HTML, display \n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67cd1e3e-8527-4a8f-ba90-e700ae7b20ad",
      "metadata": {
        "gather": {
          "logged": 1713624249031
        }
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b56a94-0471-41c3-b441-3a73ff5dedfc",
      "metadata": {},
      "source": [
        "### Get the Tool - DocSearch Agent, ChatGPT (more agents can be included - CSV Agent, SQL Agent, Web Search Agent, ChatGPT, API Agent)\n",
        "\n",
        "**Consider the following concept:** 기본적으로 특정 작업을 수행하도록 설계된 소프트웨어 개체인 에이전트에는 도구가 탑재될 수 있습니다. 이러한 도구 자체는 각각 고유한 도구 세트를 보유한 다른 에이전트가 될 수 있습니다. 이렇게 하면 도구가 코드 시퀀스에서 사람의 행동에 이르기까지 다양한 계층 구조를 형성하여 상호 연결된 체인을 형성할 수 있습니다. 궁극적으로 특정 작업을 해결하기 위해 협업하는 에이전트와 각각의 도구로 구성된 네트워크를 구축하는 것입니다(이것이 바로 ChatGPT입니다). 이 네트워크는 각 에이전트와 도구의 고유한 기능을 활용하여 작동하며, 작업 해결을 위한 역동적이고 효율적인 시스템을 만듭니다. \n",
        "\n",
        " `common/utils.py` 파일에서 이전 노트북에서 개발했던 각 기능에 대한 에이전트 도구 클래스를 만들었습니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "643d1650-6416-46fd-8b21-f5fb298ec063",
      "metadata": {
        "gather": {
          "logged": 1713624249241
        }
      },
      "outputs": [],
      "source": [
        "cb_handler = StdOutCallbackHandler()\n",
        "cb_manager = CallbackManager(handlers=[cb_handler])\n",
        "\n",
        "COMPLETION_TOKENS = 2000\n",
        "\n",
        "# We can run the everything with GPT3.5, but try also GPT4 and see the difference in the quality of responses\n",
        "# You will notice that GPT3.5 is not as reliable.\n",
        "\n",
        "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], \n",
        "                      temperature=0, max_tokens=COMPLETION_TOKENS)\n",
        "\n",
        "# Uncomment below if you want to see the answers streaming\n",
        "# llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True, callback_manager=cb_manager)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6a4cc93-2dd6-45eb-ac5b-5af2d31809dd",
      "metadata": {
        "gather": {
          "logged": 1713624249446
        }
      },
      "outputs": [],
      "source": [
        "doc_indexes = [\"cogsrch-index-files\"]\n",
        "doc_search = DocSearchAgent(llm=llm, indexes=doc_indexes,\n",
        "                           k=6, reranker_th=1,\n",
        "                           sas_token=os.environ['BLOB_SAS_TOKEN'],\n",
        "                           name=\"docsearch\",\n",
        "                           description=\"useful when the questions includes the term: docsearch\",\n",
        "                           callback_manager=cb_manager, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eafd5bf5-28ee-4edd-978b-384cce057257",
      "metadata": {
        "gather": {
          "logged": 1713624249651
        }
      },
      "outputs": [],
      "source": [
        "book_indexes = [\"cogsrch-index-books\"]\n",
        "book_search = DocSearchAgent(llm=llm, indexes=book_indexes,\n",
        "                           k=5, reranker_th=1,\n",
        "                           sas_token=os.environ['BLOB_SAS_TOKEN'],\n",
        "                           name=\"booksearch\",\n",
        "                           description=\"useful when the questions includes the term: booksearch\",\n",
        "                           callback_manager=cb_manager, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65465173-92f6-489d-9b48-58d109c5723e",
      "metadata": {
        "gather": {
          "logged": 1713624249855
        }
      },
      "outputs": [],
      "source": [
        "## ChatGPTTool is a custom Tool class created to talk to ChatGPT knowledge\n",
        "chatgpt_search = ChatGPTTool(llm=llm, callback_manager=cb_manager,\n",
        "                             name=\"chatgpt\",\n",
        "                            description=\"use for general questions, profile, greeting-like questions and when the questions includes the term: chatgpt\",\n",
        "                            verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179fc56a-b7e4-44a1-8b7f-68b2b4d02e13",
      "metadata": {},
      "source": [
        "### Variables/knobs to use for customization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21f11831-7578-4326-b3b3-d9b073a7149d",
      "metadata": {},
      "source": [
        "지금까지 살펴본 것처럼 GPT 스마트 검색 엔진 애플리케이션의 동작을 변경하기 위해 다이얼을 올리거나 내릴 수 있는 많은 knob가 있으며, 이를 조정할 수 있는 변수가 있습니다.\n",
        "\n",
        "- <u>llm</u>:\n",
        "  - **deployment_name**: this is the deployment name of your Azure OpenAI model. This of course dictates the level of reasoning and the amount of tokens available for the conversation. For a production system you will need gpt-4-32k. This is the model that will give you enough reasoning power to work with agents, and enough tokens to work with detailed answers and conversation memory.\n",
        "  - **temperature**: How creative you want your responses to be\n",
        "  - **max_tokens**: How long you want your responses to be. It is recommended a minimum of 500\n",
        "- <u>Tools</u>: To each tool you can add the following parameters to modify the defaults (set in utils.py), these are very important since they are part of the system prompt and determines what tool to use and when.\n",
        "  - **name**: the name of the tool\n",
        "  - **description**: when the brain agent should use this tool\n",
        "- <u>DocSearchAgent</u>: \n",
        "  - **k**: The top k results per index from the text search action\n",
        "  - **similarity_k**: top k results combined from the vector search action\n",
        "  - **reranker_th**: threshold of the semantic search reranker. Picks results that are above the threshold. Max possible score=4\n",
        "  \n",
        "in `utils.py` you can also tune:\n",
        "- <u>model_tokens_limit</u>: In this function you can edit what is the maximum allows of tokens reserve for the content. Remember that the remaining will be for the system prompt plus the answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9ee1058-debb-4f97-92a4-999e0c4e0386",
      "metadata": {},
      "source": [
        "### Test the Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473222f1-b423-49f3-98e7-ab70dcf47bd6",
      "metadata": {
        "gather": {
          "logged": 1713624258864
        }
      },
      "outputs": [],
      "source": [
        "# Test the Document Search Tool with a question that we know it has the answer for\n",
        "printmd(doc_search.run(\"what is the responsibility of Manager of Human Resources?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46a5ed66-e7ff-43bd-829f-c028476d2593",
      "metadata": {
        "gather": {
          "logged": 1713624263600
        }
      },
      "outputs": [],
      "source": [
        "# Test the other index created manually\n",
        "printmd(book_search.run(\"Can I move, backup, and restore indexes?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f70501c2-03d0-4072-b451-ddb92f4add56",
      "metadata": {
        "gather": {
          "logged": 1713624267914
        }
      },
      "outputs": [],
      "source": [
        "# Test the ChatGPTWrapper Search Tool\n",
        "printmd(chatgpt_search.run(\"what is the function in python that allows me to get a random number?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c0ff658-b75a-4960-8576-65472844ad05",
      "metadata": {},
      "source": [
        "### Define what tools are we going to give to our brain agent\n",
        "\n",
        "Go to `common/utils.py` to check the tools definition and the instructions on what tool to use when"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d018c884-5c91-4a35-90e3-6a5a6e510c25",
      "metadata": {
        "gather": {
          "logged": 1713624268142
        }
      },
      "outputs": [],
      "source": [
        "tools = [doc_search, book_search, chatgpt_search]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27699991-00d8-4f0a-8511-e03e530910c3",
      "metadata": {},
      "source": [
        "# Option 1: Using OpenAI functions as router"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66aed5eb-846d-44d1-acf1-04b8ff931d30",
      "metadata": {},
      "source": [
        "질문을 올바른 도구로 라우팅하는 방법이 필요하며, 이를 위한 한 가지 방법은 도구 API(모델 1106 이상)를 통해 OpenAI 모델 함수를 사용하는 것입니다. 이렇게 하려면 이러한 도구/함수를 모델에 바인딩하고 모델이 적합한 도구로 응답하도록 해야 합니다.\n",
        "\n",
        "이 옵션의 장점은 전문가(Agent Tool)와 사용자 사이에 다른 Agent가 중간에 끼어 있지 않다는 것입니다. 각 에이전트 도구가 직접 응답합니다. 또한 여러 도구를 병렬로 호출할 수 있다는 장점도 있습니다.\n",
        "\n",
        "**Note**: 이 방법에서는 각 Agent가 동일한 시스템 프로필 프롬프트를 사용하여 동일한 응답 가이드라인을 준수하는 것이 중요합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "218163af-2279-4891-8699-7f9f291c49f6",
      "metadata": {
        "gather": {
          "logged": 1713624268383
        }
      },
      "outputs": [],
      "source": [
        "llm_with_tools = llm.bind_tools(tools)\n",
        "tool_map = {tool.name: tool for tool in tools}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c5e8efd-b907-4157-99f8-15a44a63f17d",
      "metadata": {
        "gather": {
          "logged": 1713624268620
        }
      },
      "outputs": [],
      "source": [
        "def call_tool(tool_invocation: dict) -> Union[str, Runnable]:\n",
        "    \"\"\"Function for dynamically constructing the end of the chain based on the model-selected tool.\"\"\"\n",
        "    tool = tool_map[tool_invocation[\"type\"]]\n",
        "    return RunnablePassthrough.assign(output=itemgetter(\"args\") | tool)\n",
        "\n",
        "def print_response(result: List):\n",
        "    for answer in result:\n",
        "        printmd(\"**\"+answer[\"type\"] + \"**\" + \": \" + answer[\"output\"])\n",
        "        printmd(\"----\")\n",
        "      \n",
        "# .map() allows us to apply a function to a list of inputs.\n",
        "call_tool_list = RunnableLambda(call_tool).map()\n",
        "agent = llm_with_tools | JsonOutputToolsParser() | call_tool_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec71da3f-097b-4b56-bfcb-c5ed241d8cf7",
      "metadata": {
        "gather": {
          "logged": 1713624268952
        }
      },
      "outputs": [],
      "source": [
        "result = agent.invoke(\"hi, how are you, what is your name?\")\n",
        "print_response(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63682613-daa3-49fa-9fe0-6e5af8ff05ee",
      "metadata": {
        "gather": {
          "logged": 1713624272793
        }
      },
      "outputs": [],
      "source": [
        "result = agent.invoke(\"Who is the current president of France?\")\n",
        "print_response(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f58b57b-51cb-433c-b6a8-376e6aa06e12",
      "metadata": {
        "gather": {
          "logged": 1713624280699
        }
      },
      "outputs": [],
      "source": [
        "result = agent.invoke(\"docsearch,chatgpt, what is the responsibility of Manager of Human Resources?\")\n",
        "print_response(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb036da4-825f-45a4-a08f-c5a272c8f895",
      "metadata": {},
      "source": [
        "# Option 2: Using a user facing agent that calls the agent tools experts\n",
        "\n",
        "이 방법을 사용하면 사용자와 대화하고 전문가(에이전트 도구)와도 대화하는 User Facing Agent를 만들 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cc02389-cf52-4a5f-b4a1-2820ee5d8116",
      "metadata": {
        "tags": []
      },
      "source": [
        "### Initialize the brain agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea67e969-26b3-4e6f-a6c0-16780ed418e3",
      "metadata": {
        "gather": {
          "logged": 1713624281019
        }
      },
      "outputs": [],
      "source": [
        "agent = create_openai_tools_agent(llm, tools, CUSTOM_CHATBOT_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9d2d5b4-0145-402e-a620-0fe3f3548acf",
      "metadata": {
        "gather": {
          "logged": 1713624281250
        }
      },
      "outputs": [],
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ffef69-5dcd-423a-802d-7a0c419c7e46",
      "metadata": {
        "gather": {
          "logged": 1713624281471
        }
      },
      "outputs": [],
      "source": [
        "def get_session_history(session_id: str, user_id: str) -> CosmosDBChatMessageHistory:\n",
        "    cosmos = CosmosDBChatMessageHistory(\n",
        "        cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
        "        cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
        "        cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
        "        connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
        "        session_id=session_id,\n",
        "        user_id=user_id\n",
        "        )\n",
        "\n",
        "    # prepare the cosmosdb instance\n",
        "    cosmos.prepare_cosmos()\n",
        "    return cosmos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73e389f9-17cc-4c12-80e0-ab671b46bf37",
      "metadata": {
        "gather": {
          "logged": 1713624281709
        }
      },
      "outputs": [],
      "source": [
        "brain_agent_executor = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"question\",\n",
        "    history_messages_key=\"history\",\n",
        "    history_factory_config=[\n",
        "        ConfigurableFieldSpec(\n",
        "            id=\"user_id\",\n",
        "            annotation=str,\n",
        "            name=\"User ID\",\n",
        "            description=\"Unique identifier for the user.\",\n",
        "            default=\"\",\n",
        "            is_shared=True,\n",
        "        ),\n",
        "        ConfigurableFieldSpec(\n",
        "            id=\"session_id\",\n",
        "            annotation=str,\n",
        "            name=\"Session ID\",\n",
        "            description=\"Unique identifier for the conversation.\",\n",
        "            default=\"\",\n",
        "            is_shared=True,\n",
        "        ),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "601fce84-4a02-41a6-8ae2-f692174d4cc8",
      "metadata": {
        "gather": {
          "logged": 1713624282497
        }
      },
      "outputs": [],
      "source": [
        "# This is where we configure the session id and user id\n",
        "random_session_id = \"session\"+ str(random.randint(1, 1000))\n",
        "ramdom_user_id = \"user\"+ str(random.randint(1, 1000))\n",
        "\n",
        "config={\"configurable\": {\"session_id\": random_session_id, \"user_id\": ramdom_user_id}}\n",
        "print(random_session_id, ramdom_user_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4904a07d-b857-45d7-86ac-c7cade3e9080",
      "metadata": {},
      "source": [
        "### Let's talk to our GPT Smart Search Engine chat bot now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b37988b-9fb4-4958-bc17-d58d8dac8bb7",
      "metadata": {
        "gather": {
          "logged": 1713624282763
        }
      },
      "outputs": [],
      "source": [
        "# This question should not use any tool, the brain agent should answer it without the use of any tool\n",
        "printmd(brain_agent_executor.invoke({\"question\": \"Hi, I'm Pablo Marin, how are you doing today?\"}, config=config)[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a070c558-3963-40ef-b94e-365324ee3d20",
      "metadata": {
        "gather": {
          "logged": 1713624283655
        }
      },
      "outputs": [],
      "source": [
        "printmd(brain_agent_executor.invoke({\"question\": \"what is your name and what do you do?\"}, config=config)[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebdc3ad9-ad59-4135-87f6-e86728a11b71",
      "metadata": {
        "gather": {
          "logged": 1713624291659
        }
      },
      "outputs": [],
      "source": [
        "printmd(brain_agent_executor.invoke({\"question\": \"booksearch, Can I move indexes?\"}, \n",
        "                                    config=config)[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0b33f9-75fa-4a3e-b9d8-8fd30dbfd3fc",
      "metadata": {
        "gather": {
          "logged": 1713624296112
        }
      },
      "outputs": [],
      "source": [
        "printmd(brain_agent_executor.invoke({\"question\": \"chatgpt, tell me the formula in physics for momentum\"}, config=config)[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f354eb-884d-4fd3-842e-a8adc3b09a70",
      "metadata": {
        "gather": {
          "logged": 1713624312632
        }
      },
      "outputs": [],
      "source": [
        "printmd(brain_agent_executor.invoke({\"question\": \"docsearch, what is the responsibility of Manager of Human Resources?\"}, config=config)[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5ded8d9-0bfe-4e16-be3f-382271c120a9",
      "metadata": {
        "gather": {
          "logged": 1713624314364
        }
      },
      "outputs": [],
      "source": [
        "printmd(brain_agent_executor.invoke({\"question\": \"Thank you Jarvis!\"}, config=config)[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8baf56e",
      "metadata": {},
      "source": [
        "### Let's talk to our GPT Smart Search Engine chat bot with more questions and validate the responses from the chat bot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96a54fc7-ec9b-4ced-9e17-c65d00aa97f6",
      "metadata": {},
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c48d899-bd7b-4081-a656-e8d9e597220d",
      "metadata": {},
      "source": [
        "방금 GPT 스마트 검색 엔진을 구축했습니다!\n",
        "이 노트북에서 우리는 사용자의 질문에 답하기 위해 어떤 도구를 사용할지 결정하는 의사 결정 에이전트인 두뇌를 만들었습니다. 이것이 바로 스마트 채팅 봇을 만들기 위해 필요한 것이었습니다.\n",
        "\n",
        "API에 연결하고, 파일 시스템을 다루고, 심지어 사람을 도구로 사용하는 등 다양한 작업을 수행할 수 있는 많은 도구가 있습니다. 자세한 내용은 [여기](https://python.langchain.com/docs/integrations/tools/)를 참조하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9969ed7e-3680-4853-b750-675a42d3b9ea",
      "metadata": {},
      "source": [
        "# NEXT\n",
        "이제 지금까지 빌드한 모든 기능과 프롬프트를 사용하여 웹 애플리케이션을 빌드할 차례입니다.\n",
        "다음 노트북에서 빌드 방법을 안내해 드리겠습니다.\n",
        "\n",
        "\n",
        "1) 봇 API 백엔드\n",
        "2) 검색 및 웹챗 인터페이스가 있는 프런트엔드 UI"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
